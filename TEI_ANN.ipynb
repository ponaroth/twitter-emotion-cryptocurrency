{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS4662 \n",
    "## Group Project: Twitter Emotion Identification\n",
    "### Instructor: Dr. Mohammad Porhomayoun\n",
    "\n",
    "### Ponaroth Eab\n",
    "### Using Artificial Neural Network\n",
    "\n",
    "Spring 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import Normalizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "json_list = ['anger', 'fear', 'greed', 'hateful', 'joy', 'sadness']\n",
    "\n",
    "all_list = []\n",
    "limit = 10000\n",
    "\n",
    "for name in json_list:\n",
    "    # load json data as a list of strings\n",
    "    with open('raw_data/'+ name + '.json') as my_file:\n",
    "        myfile = json.load(my_file)\n",
    "        count = 0\n",
    "        \n",
    "        # turn list to a list of tuples and append to all_list (only 10,000 from each list) \n",
    "        for i in myfile:\n",
    "            if count < limit:\n",
    "                all_list.append((i, name))\n",
    "                count = count + 1\n",
    "                \n",
    "            else:\n",
    "                break\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Sad thing is sheep will buy into this POS https://t.co/hpeo1CSC70',\n",
       " 'sadness')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(np.array(list).reshape(-1,2), columns = [\"comment\", \"emotion\"])\n",
    "df = pd.DataFrame(all_list, columns=['comment', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomize the items inside dataframe\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pump and Dump.\\n\\nRun by fake Tether.</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115% Profit on #TRX - BitMEX Binance Free Cryp...</td>\n",
       "      <td>greed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @MikesBrideKatie: Meanwhile video clips of ...</td>\n",
       "      <td>hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Earning #cryptocurrency for selling my stuff o...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SHIT ON IT</td>\n",
       "      <td>hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53356</th>\n",
       "      <td>Governments, especially totalitarian ones, hat...</td>\n",
       "      <td>hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53357</th>\n",
       "      <td>Earning #cryptocurrency for selling my stuff o...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53358</th>\n",
       "      <td>The project is just a bomb, the guys are worki...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53359</th>\n",
       "      <td>Adam Hession is the lad in school that is anno...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53360</th>\n",
       "      <td>Ethereum (ETH) Price Could Weaken In Short Ter...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53361 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment    label\n",
       "0                  Pump and Dump.\\n\\nRun by fake Tether.     fear\n",
       "1      115% Profit on #TRX - BitMEX Binance Free Cryp...    greed\n",
       "2      RT @MikesBrideKatie: Meanwhile video clips of ...  hateful\n",
       "3      Earning #cryptocurrency for selling my stuff o...     fear\n",
       "4                                             SHIT ON IT  hateful\n",
       "...                                                  ...      ...\n",
       "53356  Governments, especially totalitarian ones, hat...  hateful\n",
       "53357  Earning #cryptocurrency for selling my stuff o...     fear\n",
       "53358  The project is just a bomb, the guys are worki...      joy\n",
       "53359  Adam Hession is the lad in school that is anno...    anger\n",
       "53360  Ethereum (ETH) Price Could Weaken In Short Ter...     fear\n",
       "\n",
       "[53361 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "greed      10000\n",
       "hateful    10000\n",
       "fear       10000\n",
       "joy        10000\n",
       "sadness     9765\n",
       "anger       3596\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = df.comment\n",
    "y = df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into testing and training:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42688,)\n",
      "(10673,)\n",
      "(42688,)\n",
      "(10673,)\n"
     ]
    }
   ],
   "source": [
    "# examine the object shapes\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Hidden Layer with 3 neurons:\n",
    "my_ANN = MLPClassifier(hidden_layer_sizes=(3,), activation= 'logistic', \n",
    "                       solver='adam', alpha=1e-5, random_state=1, \n",
    "                       learning_rate_init = 0.1, verbose=True, tol=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42688, 81332)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit and transform X_train into X_train_dtm\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "\n",
    "X_train_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10673, 81332)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform X_test into X_test_dtm\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "X_test_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.58981224\n",
      "Iteration 2, loss = 0.24891376\n",
      "Iteration 3, loss = 0.22001534\n",
      "Iteration 4, loss = 0.21053045\n",
      "Iteration 5, loss = 0.20522883\n",
      "Iteration 6, loss = 0.20112858\n",
      "Iteration 7, loss = 0.20099487\n",
      "Iteration 8, loss = 0.20716413\n",
      "Iteration 9, loss = 0.19417642\n",
      "Iteration 10, loss = 0.18654148\n",
      "Iteration 11, loss = 0.18428149\n",
      "Iteration 12, loss = 0.18623239\n",
      "Iteration 13, loss = 0.20206095\n",
      "Iteration 14, loss = 0.17941599\n",
      "Iteration 15, loss = 0.18242487\n",
      "Iteration 16, loss = 0.18321286\n",
      "Iteration 17, loss = 0.18479406\n",
      "Iteration 18, loss = 0.18157932\n",
      "Iteration 19, loss = 0.18303848\n",
      "Iteration 20, loss = 0.18667198\n",
      "Iteration 21, loss = 0.17862962\n",
      "Iteration 22, loss = 0.17393844\n",
      "Iteration 23, loss = 0.17375750\n",
      "Iteration 24, loss = 0.18749656\n",
      "Iteration 25, loss = 0.17904399\n",
      "Iteration 26, loss = 0.18093449\n",
      "Iteration 27, loss = 0.19934276\n",
      "Iteration 28, loss = 0.19163642\n",
      "Iteration 29, loss = 0.18681951\n",
      "Iteration 30, loss = 0.18615587\n",
      "Iteration 31, loss = 0.18362854\n",
      "Iteration 32, loss = 0.18467765\n",
      "Iteration 33, loss = 0.18513045\n",
      "Iteration 34, loss = 0.18496489\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "              learning_rate_init=0.1, max_fun=15000, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training on the training set:\n",
    "my_ANN.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger' 'anger' 'hateful' ... 'fear' 'joy' 'sadness']\n"
     ]
    }
   ],
   "source": [
    "# Testing on the testing set:\n",
    "y_predict_ann = my_ANN.predict(X_test_dtm)\n",
    "print(y_predict_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " accuracy:  0.9071488803522908\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# We can now compare the \"predicted labels\" for the Testing Set with its \"actual labels\" to evaluate the accuracy \n",
    "score_ann = accuracy_score(y_test, y_predict_ann)\n",
    "print('\\n','accuracy: ', score_ann)\n",
    "# tried preprocessing normalize and scale, but didn't help with accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.62      0.93      0.74       773\n",
      "        fear       0.97      0.92      0.94      2009\n",
      "       greed       0.90      0.93      0.92      1975\n",
      "     hateful       0.96      0.77      0.86      2041\n",
      "         joy       0.95      0.95      0.95      1938\n",
      "     sadness       0.94      0.96      0.95      1937\n",
      "\n",
      "    accuracy                           0.91     10673\n",
      "   macro avg       0.89      0.91      0.89     10673\n",
      "weighted avg       0.92      0.91      0.91     10673\n",
      "\n",
      "[[ 720    1    5   29    5   13]\n",
      " [   7 1848  110    9   21   14]\n",
      " [   3   32 1839    7   58   36]\n",
      " [ 388   12   10 1574    7   50]\n",
      " [   9   13   52    7 1844   13]\n",
      " [  39    3   20    9    9 1857]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# print classification report\n",
    "print(classification_report(y_test, y_predict_ann))\n",
    "cm = confusion_matrix(y_test, y_predict_ann)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=MLPClassifier(activation='logistic', alpha=1e-05,\n",
       "                                     batch_size='auto', beta_1=0.9,\n",
       "                                     beta_2=0.999, early_stopping=False,\n",
       "                                     epsilon=1e-08, hidden_layer_sizes=(3,),\n",
       "                                     learning_rate='constant',\n",
       "                                     learning_rate_init=0.1, max_fun=15000,\n",
       "                                     max_iter=200, momentum=0.9,\n",
       "                                     n_iter_no_change=10,\n",
       "                                     nesterovs_momentum=True, power_t=0.5,\n",
       "                                     random_state=1, shuffle=True,\n",
       "                                     solver='adam', tol=0.0001,\n",
       "                                     validation_fraction=0.1, verbose=True,\n",
       "                                     warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'hidden_layer_sizes': [(3,), (6,), (9,), (12,), (15,),\n",
       "                                                (18,), (21,)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a range for the \"number of neurons\" in the hidden layer for a network with 1 hidden layer\n",
    "# in this case neuron number is 1-9\n",
    "neuron_number = [(i,) for i in range(3,23,3)]\n",
    "\n",
    "# create a dictionary for grid parameter:\n",
    "param_grid = dict(hidden_layer_sizes = neuron_number)\n",
    "\n",
    "# creat the grid, and define the metric for evaluating the model: \n",
    "grid = GridSearchCV(my_ANN, param_grid, cv=10, scoring='accuracy', verbose=True)\n",
    "\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 7 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.22517596\n",
      "Iteration 2, loss = 0.37150850\n",
      "Iteration 3, loss = 0.19368216\n",
      "Iteration 4, loss = 0.16253164\n",
      "Iteration 5, loss = 0.12901140\n",
      "Iteration 6, loss = 0.12836144\n",
      "Iteration 7, loss = 0.10955305\n",
      "Iteration 8, loss = 0.10933124\n",
      "Iteration 9, loss = 0.12180485\n",
      "Iteration 10, loss = 0.11359013\n",
      "Iteration 11, loss = 0.09474571\n",
      "Iteration 12, loss = 0.09397957\n",
      "Iteration 13, loss = 0.08596055\n",
      "Iteration 14, loss = 0.08013062\n",
      "Iteration 15, loss = 0.08246686\n",
      "Iteration 16, loss = 0.08122290\n",
      "Iteration 17, loss = 0.07732008\n",
      "Iteration 18, loss = 0.07439696\n",
      "Iteration 19, loss = 0.08002192\n",
      "Iteration 20, loss = 0.07851521\n",
      "Iteration 21, loss = 0.08003967\n",
      "Iteration 22, loss = 0.07330170\n",
      "Iteration 23, loss = 0.07380136\n",
      "Iteration 24, loss = 0.09889719\n",
      "Iteration 25, loss = 0.11105544\n",
      "Iteration 26, loss = 0.08164519\n",
      "Iteration 27, loss = 0.07618557\n",
      "Iteration 28, loss = 0.07412820\n",
      "Iteration 29, loss = 0.07722438\n",
      "Iteration 30, loss = 0.11874844\n",
      "Iteration 31, loss = 0.09494354\n",
      "Iteration 32, loss = 0.08276561\n",
      "Iteration 33, loss = 0.07558762\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22285142\n",
      "Iteration 2, loss = 0.37521572\n",
      "Iteration 3, loss = 0.20076770\n",
      "Iteration 4, loss = 0.14302211\n",
      "Iteration 5, loss = 0.12207220\n",
      "Iteration 6, loss = 0.12403300\n",
      "Iteration 7, loss = 0.11640356\n",
      "Iteration 8, loss = 0.10568941\n",
      "Iteration 9, loss = 0.09826400\n",
      "Iteration 10, loss = 0.09567740\n",
      "Iteration 11, loss = 0.10238285\n",
      "Iteration 12, loss = 0.10068163\n",
      "Iteration 13, loss = 0.13040744\n",
      "Iteration 14, loss = 0.12670336\n",
      "Iteration 15, loss = 0.09393298\n",
      "Iteration 16, loss = 0.08857953\n",
      "Iteration 17, loss = 0.08834776\n",
      "Iteration 18, loss = 0.08560933\n",
      "Iteration 19, loss = 0.07786332\n",
      "Iteration 20, loss = 0.07712625\n",
      "Iteration 21, loss = 0.07817665\n",
      "Iteration 22, loss = 0.07952495\n",
      "Iteration 23, loss = 0.08235975\n",
      "Iteration 24, loss = 0.09359796\n",
      "Iteration 25, loss = 0.08281547\n",
      "Iteration 26, loss = 0.08239623\n",
      "Iteration 27, loss = 0.08157570\n",
      "Iteration 28, loss = 0.07843995\n",
      "Iteration 29, loss = 0.08262021\n",
      "Iteration 30, loss = 0.08530981\n",
      "Iteration 31, loss = 0.08106142\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26105128\n",
      "Iteration 2, loss = 0.43524022\n",
      "Iteration 3, loss = 0.30152705\n",
      "Iteration 4, loss = 0.25200196\n",
      "Iteration 5, loss = 0.23064596\n",
      "Iteration 6, loss = 0.19464598\n",
      "Iteration 7, loss = 0.15059888\n",
      "Iteration 8, loss = 0.12869544\n",
      "Iteration 9, loss = 0.13152535\n",
      "Iteration 10, loss = 0.11974616\n",
      "Iteration 11, loss = 0.11155658\n",
      "Iteration 12, loss = 0.10693935\n",
      "Iteration 13, loss = 0.10725341\n",
      "Iteration 14, loss = 0.10213062\n",
      "Iteration 15, loss = 0.09966010\n",
      "Iteration 16, loss = 0.10032548\n",
      "Iteration 17, loss = 0.09567279\n",
      "Iteration 18, loss = 0.08816232\n",
      "Iteration 19, loss = 0.08625448\n",
      "Iteration 20, loss = 0.08910012\n",
      "Iteration 21, loss = 0.10073938\n",
      "Iteration 22, loss = 0.09566411\n",
      "Iteration 23, loss = 0.09217641\n",
      "Iteration 24, loss = 0.08993246\n",
      "Iteration 25, loss = 0.08707069\n",
      "Iteration 26, loss = 0.08940815\n",
      "Iteration 27, loss = 0.09678154\n",
      "Iteration 28, loss = 0.09111479\n",
      "Iteration 29, loss = 0.09400755\n",
      "Iteration 30, loss = 0.14265270\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22913218\n",
      "Iteration 2, loss = 0.42550836\n",
      "Iteration 3, loss = 0.29265747\n",
      "Iteration 4, loss = 0.25027773\n",
      "Iteration 5, loss = 0.20760545\n",
      "Iteration 6, loss = 0.19483721\n",
      "Iteration 7, loss = 0.17091574\n",
      "Iteration 8, loss = 0.15832391\n",
      "Iteration 9, loss = 0.15306212\n",
      "Iteration 10, loss = 0.15310630\n",
      "Iteration 11, loss = 0.13408583\n",
      "Iteration 12, loss = 0.12273550\n",
      "Iteration 13, loss = 0.10918876\n",
      "Iteration 14, loss = 0.10310329\n",
      "Iteration 15, loss = 0.09687314\n",
      "Iteration 16, loss = 0.09260582\n",
      "Iteration 17, loss = 0.09276659\n",
      "Iteration 18, loss = 0.08973279\n",
      "Iteration 19, loss = 0.08198187\n",
      "Iteration 20, loss = 0.09231617\n",
      "Iteration 21, loss = 0.09443014\n",
      "Iteration 22, loss = 0.08597896\n",
      "Iteration 23, loss = 0.08098667\n",
      "Iteration 24, loss = 0.07901616\n",
      "Iteration 25, loss = 0.07846109\n",
      "Iteration 26, loss = 0.08166106\n",
      "Iteration 27, loss = 0.07739535\n",
      "Iteration 28, loss = 0.07682197\n",
      "Iteration 29, loss = 0.07455265\n",
      "Iteration 30, loss = 0.07231855\n",
      "Iteration 31, loss = 0.07191965\n",
      "Iteration 32, loss = 0.07200253\n",
      "Iteration 33, loss = 0.07516214\n",
      "Iteration 34, loss = 0.07758939\n",
      "Iteration 35, loss = 0.07441237\n",
      "Iteration 36, loss = 0.07399216\n",
      "Iteration 37, loss = 0.07210760\n",
      "Iteration 38, loss = 0.07220585\n",
      "Iteration 39, loss = 0.07047973\n",
      "Iteration 40, loss = 0.07472244\n",
      "Iteration 41, loss = 0.07134054\n",
      "Iteration 42, loss = 0.07358254\n",
      "Iteration 43, loss = 0.08515450\n",
      "Iteration 44, loss = 0.08821436\n",
      "Iteration 45, loss = 0.12419670\n",
      "Iteration 46, loss = 0.11086980\n",
      "Iteration 47, loss = 0.13981123\n",
      "Iteration 48, loss = 0.13744159\n",
      "Iteration 49, loss = 0.10051393\n",
      "Iteration 50, loss = 0.08772818\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22933791\n",
      "Iteration 2, loss = 0.41487152\n",
      "Iteration 3, loss = 0.29790119\n",
      "Iteration 4, loss = 0.27168063\n",
      "Iteration 5, loss = 0.25094376\n",
      "Iteration 6, loss = 0.22561512\n",
      "Iteration 7, loss = 0.20308430\n",
      "Iteration 8, loss = 0.20340900\n",
      "Iteration 9, loss = 0.19842174\n",
      "Iteration 10, loss = 0.17571900\n",
      "Iteration 11, loss = 0.16147932\n",
      "Iteration 12, loss = 0.15607021\n",
      "Iteration 13, loss = 0.16047532\n",
      "Iteration 14, loss = 0.16964538\n",
      "Iteration 15, loss = 0.15808220\n",
      "Iteration 16, loss = 0.14500304\n",
      "Iteration 17, loss = 0.13760371\n",
      "Iteration 18, loss = 0.13301084\n",
      "Iteration 19, loss = 0.12957147\n",
      "Iteration 20, loss = 0.12611542\n",
      "Iteration 21, loss = 0.12476364\n",
      "Iteration 22, loss = 0.14068973\n",
      "Iteration 23, loss = 0.12803692\n",
      "Iteration 24, loss = 0.13524740\n",
      "Iteration 25, loss = 0.12968516\n",
      "Iteration 26, loss = 0.12418773\n",
      "Iteration 27, loss = 0.12090111\n",
      "Iteration 28, loss = 0.11845600\n",
      "Iteration 29, loss = 0.11748622\n",
      "Iteration 30, loss = 0.11648580\n",
      "Iteration 31, loss = 0.11508283\n",
      "Iteration 32, loss = 0.11755824\n",
      "Iteration 33, loss = 0.12244878\n",
      "Iteration 34, loss = 0.12585003\n",
      "Iteration 35, loss = 0.11305950\n",
      "Iteration 36, loss = 0.12908391\n",
      "Iteration 37, loss = 0.13221067\n",
      "Iteration 38, loss = 0.13432723\n",
      "Iteration 39, loss = 0.13259024\n",
      "Iteration 40, loss = 0.13199964\n",
      "Iteration 41, loss = 0.12785597\n",
      "Iteration 42, loss = 0.11754447\n",
      "Iteration 43, loss = 0.11684541\n",
      "Iteration 44, loss = 0.11917477\n",
      "Iteration 45, loss = 0.10989110\n",
      "Iteration 46, loss = 0.11358050\n",
      "Iteration 47, loss = 0.10742946\n",
      "Iteration 48, loss = 0.11008475\n",
      "Iteration 49, loss = 0.10983152\n",
      "Iteration 50, loss = 0.10639037\n",
      "Iteration 51, loss = 0.10379567\n",
      "Iteration 52, loss = 0.10278553\n",
      "Iteration 53, loss = 0.10237779\n",
      "Iteration 54, loss = 0.10312900\n",
      "Iteration 55, loss = 0.10236932\n",
      "Iteration 56, loss = 0.10110376\n",
      "Iteration 57, loss = 0.10837423\n",
      "Iteration 58, loss = 0.11601948\n",
      "Iteration 59, loss = 0.11566329\n",
      "Iteration 60, loss = 0.12471552\n",
      "Iteration 61, loss = 0.12223300\n",
      "Iteration 62, loss = 0.11485537\n",
      "Iteration 63, loss = 0.11613308\n",
      "Iteration 64, loss = 0.11170912\n",
      "Iteration 65, loss = 0.10974278\n",
      "Iteration 66, loss = 0.10635163\n",
      "Iteration 67, loss = 0.12024116\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21811726\n",
      "Iteration 2, loss = 0.42387495\n",
      "Iteration 3, loss = 0.29318990\n",
      "Iteration 4, loss = 0.26951300\n",
      "Iteration 5, loss = 0.23541399\n",
      "Iteration 6, loss = 0.20847178\n",
      "Iteration 7, loss = 0.18259340\n",
      "Iteration 8, loss = 0.16059071\n",
      "Iteration 9, loss = 0.15040662\n",
      "Iteration 10, loss = 0.14877852\n",
      "Iteration 11, loss = 0.13696644\n",
      "Iteration 12, loss = 0.12263538\n",
      "Iteration 13, loss = 0.09806850\n",
      "Iteration 14, loss = 0.09077833\n",
      "Iteration 15, loss = 0.14689784\n",
      "Iteration 16, loss = 0.12306432\n",
      "Iteration 17, loss = 0.11534087\n",
      "Iteration 18, loss = 0.11582599\n",
      "Iteration 19, loss = 0.09159000\n",
      "Iteration 20, loss = 0.09521642\n",
      "Iteration 21, loss = 0.08345953\n",
      "Iteration 22, loss = 0.08588033\n",
      "Iteration 23, loss = 0.08396825\n",
      "Iteration 24, loss = 0.08013497\n",
      "Iteration 25, loss = 0.12479704\n",
      "Iteration 26, loss = 0.08947472\n",
      "Iteration 27, loss = 0.09256246\n",
      "Iteration 28, loss = 0.08372190\n",
      "Iteration 29, loss = 0.07810100\n",
      "Iteration 30, loss = 0.07544249\n",
      "Iteration 31, loss = 0.07533236\n",
      "Iteration 32, loss = 0.07604804\n",
      "Iteration 33, loss = 0.07602017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 34, loss = 0.07586827\n",
      "Iteration 35, loss = 0.07373956\n",
      "Iteration 36, loss = 0.07450073\n",
      "Iteration 37, loss = 0.07440877\n",
      "Iteration 38, loss = 0.07389413\n",
      "Iteration 39, loss = 0.07287538\n",
      "Iteration 40, loss = 0.07302174\n",
      "Iteration 41, loss = 0.07322761\n",
      "Iteration 42, loss = 0.07349314\n",
      "Iteration 43, loss = 0.07316506\n",
      "Iteration 44, loss = 0.07182438\n",
      "Iteration 45, loss = 0.07309639\n",
      "Iteration 46, loss = 0.07729228\n",
      "Iteration 47, loss = 0.07331825\n",
      "Iteration 48, loss = 0.07271158\n",
      "Iteration 49, loss = 0.07353461\n",
      "Iteration 50, loss = 0.07339589\n",
      "Iteration 51, loss = 0.07244493\n",
      "Iteration 52, loss = 0.07421627\n",
      "Iteration 53, loss = 0.07224033\n",
      "Iteration 54, loss = 0.07306058\n",
      "Iteration 55, loss = 0.08692068\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24838732\n",
      "Iteration 2, loss = 0.44498139\n",
      "Iteration 3, loss = 0.27433990\n",
      "Iteration 4, loss = 0.21798374\n",
      "Iteration 5, loss = 0.17535327\n",
      "Iteration 6, loss = 0.15417648\n",
      "Iteration 7, loss = 0.13497129\n",
      "Iteration 8, loss = 0.12820481\n",
      "Iteration 9, loss = 0.11775320\n",
      "Iteration 10, loss = 0.12239403\n",
      "Iteration 11, loss = 0.11780308\n",
      "Iteration 12, loss = 0.12397116\n",
      "Iteration 13, loss = 0.12785718\n",
      "Iteration 14, loss = 0.11497443\n",
      "Iteration 15, loss = 0.10891463\n",
      "Iteration 16, loss = 0.09653625\n",
      "Iteration 17, loss = 0.09362808\n",
      "Iteration 18, loss = 0.10593667\n",
      "Iteration 19, loss = 0.10737012\n",
      "Iteration 20, loss = 0.10295661\n",
      "Iteration 21, loss = 0.09134607\n",
      "Iteration 22, loss = 0.08771214\n",
      "Iteration 23, loss = 0.08106548\n",
      "Iteration 24, loss = 0.08754329\n",
      "Iteration 25, loss = 0.09386918\n",
      "Iteration 26, loss = 0.08329592\n",
      "Iteration 27, loss = 0.07878301\n",
      "Iteration 28, loss = 0.09534626\n",
      "Iteration 29, loss = 0.10765182\n",
      "Iteration 30, loss = 0.07736932\n",
      "Iteration 31, loss = 0.09796076\n",
      "Iteration 32, loss = 0.10183099\n",
      "Iteration 33, loss = 0.08633056\n",
      "Iteration 34, loss = 0.08862557\n",
      "Iteration 35, loss = 0.07884077\n",
      "Iteration 36, loss = 0.07342839\n",
      "Iteration 37, loss = 0.07318931\n",
      "Iteration 38, loss = 0.07127930\n",
      "Iteration 39, loss = 0.07097306\n",
      "Iteration 40, loss = 0.07681727\n",
      "Iteration 41, loss = 0.07052078\n",
      "Iteration 42, loss = 0.07119462\n",
      "Iteration 43, loss = 0.06900545\n",
      "Iteration 44, loss = 0.06738993\n",
      "Iteration 45, loss = 0.06797235\n",
      "Iteration 46, loss = 0.07262804\n",
      "Iteration 47, loss = 0.06896273\n",
      "Iteration 48, loss = 0.06768222\n",
      "Iteration 49, loss = 0.07327414\n",
      "Iteration 50, loss = 0.06715491\n",
      "Iteration 51, loss = 0.06590708\n",
      "Iteration 52, loss = 0.06660872\n",
      "Iteration 53, loss = 0.06573354\n",
      "Iteration 54, loss = 0.06603145\n",
      "Iteration 55, loss = 0.06651123\n",
      "Iteration 56, loss = 0.06637869\n",
      "Iteration 57, loss = 0.06522268\n",
      "Iteration 58, loss = 0.06250922\n",
      "Iteration 59, loss = 0.06240129\n",
      "Iteration 60, loss = 0.06243981\n",
      "Iteration 61, loss = 0.06182638\n",
      "Iteration 62, loss = 0.06162948\n",
      "Iteration 63, loss = 0.06241024\n",
      "Iteration 64, loss = 0.06369878\n",
      "Iteration 65, loss = 0.09296247\n",
      "Iteration 66, loss = 0.09221788\n",
      "Iteration 67, loss = 0.10031043\n",
      "Iteration 68, loss = 0.10020536\n",
      "Iteration 69, loss = 0.11910131\n",
      "Iteration 70, loss = 0.10772313\n",
      "Iteration 71, loss = 0.10401708\n",
      "Iteration 72, loss = 0.10481871\n",
      "Iteration 73, loss = 0.11920448\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24842136\n",
      "Iteration 2, loss = 0.46183285\n",
      "Iteration 3, loss = 0.31232699\n",
      "Iteration 4, loss = 0.26789144\n",
      "Iteration 5, loss = 0.22468969\n",
      "Iteration 6, loss = 0.20208622\n",
      "Iteration 7, loss = 0.18351353\n",
      "Iteration 8, loss = 0.16901095\n",
      "Iteration 9, loss = 0.16219366\n",
      "Iteration 10, loss = 0.13945834\n",
      "Iteration 11, loss = 0.12834701\n",
      "Iteration 12, loss = 0.11724873\n",
      "Iteration 13, loss = 0.10819264\n",
      "Iteration 14, loss = 0.10108633\n",
      "Iteration 15, loss = 0.09632920\n",
      "Iteration 16, loss = 0.09788473\n",
      "Iteration 17, loss = 0.15455003\n",
      "Iteration 18, loss = 0.11696176\n",
      "Iteration 19, loss = 0.09769527\n",
      "Iteration 20, loss = 0.09292431\n",
      "Iteration 21, loss = 0.08598328\n",
      "Iteration 22, loss = 0.08478452\n",
      "Iteration 23, loss = 0.08392201\n",
      "Iteration 24, loss = 0.08058678\n",
      "Iteration 25, loss = 0.07717520\n",
      "Iteration 26, loss = 0.07442495\n",
      "Iteration 27, loss = 0.14381035\n",
      "Iteration 28, loss = 0.09978362\n",
      "Iteration 29, loss = 0.08508167\n",
      "Iteration 30, loss = 0.08097714\n",
      "Iteration 31, loss = 0.08899644\n",
      "Iteration 32, loss = 0.07219016\n",
      "Iteration 33, loss = 0.06889132\n",
      "Iteration 34, loss = 0.06919903\n",
      "Iteration 35, loss = 0.06739694\n",
      "Iteration 36, loss = 0.06519955\n",
      "Iteration 37, loss = 0.06436888\n",
      "Iteration 38, loss = 0.06258799\n",
      "Iteration 39, loss = 0.06254942\n",
      "Iteration 40, loss = 0.06318568\n",
      "Iteration 41, loss = 0.06175197\n",
      "Iteration 42, loss = 0.06119720\n",
      "Iteration 43, loss = 0.06129818\n",
      "Iteration 44, loss = 0.06156428\n",
      "Iteration 45, loss = 0.05992508\n",
      "Iteration 46, loss = 0.06433191\n",
      "Iteration 47, loss = 0.06172045\n",
      "Iteration 48, loss = 0.06227073\n",
      "Iteration 49, loss = 0.06240626\n",
      "Iteration 50, loss = 0.06136803\n",
      "Iteration 51, loss = 0.06099166\n",
      "Iteration 52, loss = 0.06169575\n",
      "Iteration 53, loss = 0.06088309\n",
      "Iteration 54, loss = 0.06060792\n",
      "Iteration 55, loss = 0.10500853\n",
      "Iteration 56, loss = 0.11638397\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21701181\n",
      "Iteration 2, loss = 0.43472074\n",
      "Iteration 3, loss = 0.28022782\n",
      "Iteration 4, loss = 0.22683241\n",
      "Iteration 5, loss = 0.19523841\n",
      "Iteration 6, loss = 0.17122846\n",
      "Iteration 7, loss = 0.15654800\n",
      "Iteration 8, loss = 0.15177834\n",
      "Iteration 9, loss = 0.13640587\n",
      "Iteration 10, loss = 0.13071771\n",
      "Iteration 11, loss = 0.11999917\n",
      "Iteration 12, loss = 0.12200074\n",
      "Iteration 13, loss = 0.15536623\n",
      "Iteration 14, loss = 0.13207959\n",
      "Iteration 15, loss = 0.12916050\n",
      "Iteration 16, loss = 0.12084431\n",
      "Iteration 17, loss = 0.11135574\n",
      "Iteration 18, loss = 0.10931027\n",
      "Iteration 19, loss = 0.09997079\n",
      "Iteration 20, loss = 0.10038472\n",
      "Iteration 21, loss = 0.09902992\n",
      "Iteration 22, loss = 0.09601169\n",
      "Iteration 23, loss = 0.09532134\n",
      "Iteration 24, loss = 0.09956002\n",
      "Iteration 25, loss = 0.09781354\n",
      "Iteration 26, loss = 0.09502979\n",
      "Iteration 27, loss = 0.09660426\n",
      "Iteration 28, loss = 0.09484327\n",
      "Iteration 29, loss = 0.09213806\n",
      "Iteration 30, loss = 0.09246857\n",
      "Iteration 31, loss = 0.09191703\n",
      "Iteration 32, loss = 0.09933844\n",
      "Iteration 33, loss = 0.08945556\n",
      "Iteration 34, loss = 0.09897126\n",
      "Iteration 35, loss = 0.09811486\n",
      "Iteration 36, loss = 0.09796232\n",
      "Iteration 37, loss = 0.09278642\n",
      "Iteration 38, loss = 0.09256996\n",
      "Iteration 39, loss = 0.08951379\n",
      "Iteration 40, loss = 0.09596745\n",
      "Iteration 41, loss = 0.09745675\n",
      "Iteration 42, loss = 0.09316311\n",
      "Iteration 43, loss = 0.09986458\n",
      "Iteration 44, loss = 0.12780175\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23251428\n",
      "Iteration 2, loss = 0.42289656\n",
      "Iteration 3, loss = 0.27731150\n",
      "Iteration 4, loss = 0.22256866\n",
      "Iteration 5, loss = 0.19419300\n",
      "Iteration 6, loss = 0.17286387\n",
      "Iteration 7, loss = 0.15861351\n",
      "Iteration 8, loss = 0.15212383\n",
      "Iteration 9, loss = 0.13805410\n",
      "Iteration 10, loss = 0.14598786\n",
      "Iteration 11, loss = 0.14618074\n",
      "Iteration 12, loss = 0.14792940\n",
      "Iteration 13, loss = 0.13517266\n",
      "Iteration 14, loss = 0.13161647\n",
      "Iteration 15, loss = 0.11978347\n",
      "Iteration 16, loss = 0.11641070\n",
      "Iteration 17, loss = 0.10591327\n",
      "Iteration 18, loss = 0.10051303\n",
      "Iteration 19, loss = 0.10308048\n",
      "Iteration 20, loss = 0.13143735\n",
      "Iteration 21, loss = 0.17829532\n",
      "Iteration 22, loss = 0.13205177\n",
      "Iteration 23, loss = 0.11641962\n",
      "Iteration 24, loss = 0.10529215\n",
      "Iteration 25, loss = 0.11059728\n",
      "Iteration 26, loss = 0.11575252\n",
      "Iteration 27, loss = 0.10233008\n",
      "Iteration 28, loss = 0.10097017\n",
      "Iteration 29, loss = 0.09800850\n",
      "Iteration 30, loss = 0.09841586\n",
      "Iteration 31, loss = 0.11109234\n",
      "Iteration 32, loss = 0.10524956\n",
      "Iteration 33, loss = 0.09770429\n",
      "Iteration 34, loss = 0.09953883\n",
      "Iteration 35, loss = 0.09391000\n",
      "Iteration 36, loss = 0.09263486\n",
      "Iteration 37, loss = 0.09028983\n",
      "Iteration 38, loss = 0.08789296\n",
      "Iteration 39, loss = 0.08803043\n",
      "Iteration 40, loss = 0.08816759\n",
      "Iteration 41, loss = 0.08691151\n",
      "Iteration 42, loss = 0.09205154\n",
      "Iteration 43, loss = 0.08463386\n",
      "Iteration 44, loss = 0.08354206\n",
      "Iteration 45, loss = 0.08365476\n",
      "Iteration 46, loss = 0.08485978\n",
      "Iteration 47, loss = 0.08803808\n",
      "Iteration 48, loss = 0.10121369\n",
      "Iteration 49, loss = 0.09437384\n",
      "Iteration 50, loss = 0.08615467\n",
      "Iteration 51, loss = 0.08795533\n",
      "Iteration 52, loss = 0.08882183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 53, loss = 0.11648278\n",
      "Iteration 54, loss = 0.11504563\n",
      "Iteration 55, loss = 0.09204115\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.91473892\n",
      "Iteration 2, loss = 0.15834155\n",
      "Iteration 3, loss = 0.09202742\n",
      "Iteration 4, loss = 0.07415667\n",
      "Iteration 5, loss = 0.06974468\n",
      "Iteration 6, loss = 0.05782625\n",
      "Iteration 7, loss = 0.05709829\n",
      "Iteration 8, loss = 0.04930138\n",
      "Iteration 9, loss = 0.06512752\n",
      "Iteration 10, loss = 0.05872670\n",
      "Iteration 11, loss = 0.04984311\n",
      "Iteration 12, loss = 0.04640000\n",
      "Iteration 13, loss = 0.04309353\n",
      "Iteration 14, loss = 0.04262891\n",
      "Iteration 15, loss = 0.04466264\n",
      "Iteration 16, loss = 0.05848669\n",
      "Iteration 17, loss = 0.04688952\n",
      "Iteration 18, loss = 0.04438132\n",
      "Iteration 19, loss = 0.04741634\n",
      "Iteration 20, loss = 0.04188412\n",
      "Iteration 21, loss = 0.04091852\n",
      "Iteration 22, loss = 0.03854647\n",
      "Iteration 23, loss = 0.03796741\n",
      "Iteration 24, loss = 0.03650157\n",
      "Iteration 25, loss = 0.03937467\n",
      "Iteration 26, loss = 0.03688172\n",
      "Iteration 27, loss = 0.03583213\n",
      "Iteration 28, loss = 0.03760291\n",
      "Iteration 29, loss = 0.03755598\n",
      "Iteration 30, loss = 0.03572442\n",
      "Iteration 31, loss = 0.03521954\n",
      "Iteration 32, loss = 0.03567268\n",
      "Iteration 33, loss = 0.03554608\n",
      "Iteration 34, loss = 0.04503403\n",
      "Iteration 35, loss = 0.03696509\n",
      "Iteration 36, loss = 0.04020918\n",
      "Iteration 37, loss = 0.05979627\n",
      "Iteration 38, loss = 0.05985899\n",
      "Iteration 39, loss = 0.06041931\n",
      "Iteration 40, loss = 0.05743705\n",
      "Iteration 41, loss = 0.04786927\n",
      "Iteration 42, loss = 0.04483674\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.88796157\n",
      "Iteration 2, loss = 0.15399615\n",
      "Iteration 3, loss = 0.09633303\n",
      "Iteration 4, loss = 0.06717854\n",
      "Iteration 5, loss = 0.05897843\n",
      "Iteration 6, loss = 0.05103732\n",
      "Iteration 7, loss = 0.05652372\n",
      "Iteration 8, loss = 0.05315676\n",
      "Iteration 9, loss = 0.04594914\n",
      "Iteration 10, loss = 0.04415059\n",
      "Iteration 11, loss = 0.04405882\n",
      "Iteration 12, loss = 0.04348209\n",
      "Iteration 13, loss = 0.04153425\n",
      "Iteration 14, loss = 0.03828936\n",
      "Iteration 15, loss = 0.03902243\n",
      "Iteration 16, loss = 0.04199293\n",
      "Iteration 17, loss = 0.04167190\n",
      "Iteration 18, loss = 0.04839738\n",
      "Iteration 19, loss = 0.04875628\n",
      "Iteration 20, loss = 0.04463731\n",
      "Iteration 21, loss = 0.09141002\n",
      "Iteration 22, loss = 0.08868316\n",
      "Iteration 23, loss = 0.07565343\n",
      "Iteration 24, loss = 0.07299880\n",
      "Iteration 25, loss = 0.06529837\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.90094653\n",
      "Iteration 2, loss = 0.16175072\n",
      "Iteration 3, loss = 0.11033927\n",
      "Iteration 4, loss = 0.07592194\n",
      "Iteration 5, loss = 0.06456325\n",
      "Iteration 6, loss = 0.05630418\n",
      "Iteration 7, loss = 0.05542039\n",
      "Iteration 8, loss = 0.05184452\n",
      "Iteration 9, loss = 0.05100711\n",
      "Iteration 10, loss = 0.04710946\n",
      "Iteration 11, loss = 0.04990496\n",
      "Iteration 12, loss = 0.04515387\n",
      "Iteration 13, loss = 0.04238634\n",
      "Iteration 14, loss = 0.04181984\n",
      "Iteration 15, loss = 0.04095269\n",
      "Iteration 16, loss = 0.03910620\n",
      "Iteration 17, loss = 0.03614197\n",
      "Iteration 18, loss = 0.03577596\n",
      "Iteration 19, loss = 0.03461614\n",
      "Iteration 20, loss = 0.03185567\n",
      "Iteration 21, loss = 0.03299715\n",
      "Iteration 22, loss = 0.03131052\n",
      "Iteration 23, loss = 0.03192340\n",
      "Iteration 24, loss = 0.03227732\n",
      "Iteration 25, loss = 0.05104252\n",
      "Iteration 26, loss = 0.05773690\n",
      "Iteration 27, loss = 0.06523729\n",
      "Iteration 28, loss = 0.07070851\n",
      "Iteration 29, loss = 0.05942828\n",
      "Iteration 30, loss = 0.05991993\n",
      "Iteration 31, loss = 0.06514536\n",
      "Iteration 32, loss = 0.05552279\n",
      "Iteration 33, loss = 0.05640124\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.84418277\n",
      "Iteration 2, loss = 0.14303581\n",
      "Iteration 3, loss = 0.09576939\n",
      "Iteration 4, loss = 0.07534168\n",
      "Iteration 5, loss = 0.06739125\n",
      "Iteration 6, loss = 0.05573661\n",
      "Iteration 7, loss = 0.05091753\n",
      "Iteration 8, loss = 0.05413037\n",
      "Iteration 9, loss = 0.06485305\n",
      "Iteration 10, loss = 0.07690139\n",
      "Iteration 11, loss = 0.06966625\n",
      "Iteration 12, loss = 0.06323381\n",
      "Iteration 13, loss = 0.05208437\n",
      "Iteration 14, loss = 0.06167390\n",
      "Iteration 15, loss = 0.05653532\n",
      "Iteration 16, loss = 0.04763939\n",
      "Iteration 17, loss = 0.04473263\n",
      "Iteration 18, loss = 0.05845399\n",
      "Iteration 19, loss = 0.05398146\n",
      "Iteration 20, loss = 0.04825448\n",
      "Iteration 21, loss = 0.05131461\n",
      "Iteration 22, loss = 0.05162294\n",
      "Iteration 23, loss = 0.04741288\n",
      "Iteration 24, loss = 0.05405850\n",
      "Iteration 25, loss = 0.05309055\n",
      "Iteration 26, loss = 0.04214806\n",
      "Iteration 27, loss = 0.03841620\n",
      "Iteration 28, loss = 0.03776365\n",
      "Iteration 29, loss = 0.03729122\n",
      "Iteration 30, loss = 0.03495420\n",
      "Iteration 31, loss = 0.03499132\n",
      "Iteration 32, loss = 0.03451926\n",
      "Iteration 33, loss = 0.03459422\n",
      "Iteration 34, loss = 0.03719816\n",
      "Iteration 35, loss = 0.03358838\n",
      "Iteration 36, loss = 0.03326131\n",
      "Iteration 37, loss = 0.03281219\n",
      "Iteration 38, loss = 0.03236439\n",
      "Iteration 39, loss = 0.03473859\n",
      "Iteration 40, loss = 0.03554762\n",
      "Iteration 41, loss = 0.03277107\n",
      "Iteration 42, loss = 0.03205007\n",
      "Iteration 43, loss = 0.03311644\n",
      "Iteration 44, loss = 0.03206614\n",
      "Iteration 45, loss = 0.03131463\n",
      "Iteration 46, loss = 0.03202988\n",
      "Iteration 47, loss = 0.03237961\n",
      "Iteration 48, loss = 0.03584830\n",
      "Iteration 49, loss = 0.03581664\n",
      "Iteration 50, loss = 0.04874880\n",
      "Iteration 51, loss = 0.06362269\n",
      "Iteration 52, loss = 0.09334223\n",
      "Iteration 53, loss = 0.07400401\n",
      "Iteration 54, loss = 0.05854627\n",
      "Iteration 55, loss = 0.07185121\n",
      "Iteration 56, loss = 0.05409296\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.84115876\n",
      "Iteration 2, loss = 0.15671489\n",
      "Iteration 3, loss = 0.10019638\n",
      "Iteration 4, loss = 0.08343335\n",
      "Iteration 5, loss = 0.06476039\n",
      "Iteration 6, loss = 0.05775192\n",
      "Iteration 7, loss = 0.05043215\n",
      "Iteration 8, loss = 0.04574524\n",
      "Iteration 9, loss = 0.04123632\n",
      "Iteration 10, loss = 0.04744855\n",
      "Iteration 11, loss = 0.07535005\n",
      "Iteration 12, loss = 0.07988130\n",
      "Iteration 13, loss = 0.08892164\n",
      "Iteration 14, loss = 0.05789465\n",
      "Iteration 15, loss = 0.04576309\n",
      "Iteration 16, loss = 0.04600432\n",
      "Iteration 17, loss = 0.04168852\n",
      "Iteration 18, loss = 0.03995820\n",
      "Iteration 19, loss = 0.04304927\n",
      "Iteration 20, loss = 0.03938079\n",
      "Iteration 21, loss = 0.03948039\n",
      "Iteration 22, loss = 0.03716182\n",
      "Iteration 23, loss = 0.03565265\n",
      "Iteration 24, loss = 0.03434256\n",
      "Iteration 25, loss = 0.03445302\n",
      "Iteration 26, loss = 0.03407657\n",
      "Iteration 27, loss = 0.03272036\n",
      "Iteration 28, loss = 0.03317145\n",
      "Iteration 29, loss = 0.03611252\n",
      "Iteration 30, loss = 0.03361091\n",
      "Iteration 31, loss = 0.03410381\n",
      "Iteration 32, loss = 0.03520830\n",
      "Iteration 33, loss = 0.03489867\n",
      "Iteration 34, loss = 0.03652775\n",
      "Iteration 35, loss = 0.03354365\n",
      "Iteration 36, loss = 0.03335633\n",
      "Iteration 37, loss = 0.03356030\n",
      "Iteration 38, loss = 0.03785044\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.83653683\n",
      "Iteration 2, loss = 0.14446055\n",
      "Iteration 3, loss = 0.09875866\n",
      "Iteration 4, loss = 0.08455909\n",
      "Iteration 5, loss = 0.08396562\n",
      "Iteration 6, loss = 0.06462762\n",
      "Iteration 7, loss = 0.05953544\n",
      "Iteration 8, loss = 0.05318296\n",
      "Iteration 9, loss = 0.05918390\n",
      "Iteration 10, loss = 0.07031796\n",
      "Iteration 11, loss = 0.06591153\n",
      "Iteration 12, loss = 0.05774963\n",
      "Iteration 13, loss = 0.06713157\n",
      "Iteration 14, loss = 0.05127366\n",
      "Iteration 15, loss = 0.04939638\n",
      "Iteration 16, loss = 0.05397927\n",
      "Iteration 17, loss = 0.04891080\n",
      "Iteration 18, loss = 0.04618934\n",
      "Iteration 19, loss = 0.04438287\n",
      "Iteration 20, loss = 0.04410715\n",
      "Iteration 21, loss = 0.06048221\n",
      "Iteration 22, loss = 0.04843388\n",
      "Iteration 23, loss = 0.05035819\n",
      "Iteration 24, loss = 0.04686114\n",
      "Iteration 25, loss = 0.05641436\n",
      "Iteration 26, loss = 0.05881629\n",
      "Iteration 27, loss = 0.05318028\n",
      "Iteration 28, loss = 0.05122941\n",
      "Iteration 29, loss = 0.04903361\n",
      "Iteration 30, loss = 0.04580624\n",
      "Iteration 31, loss = 0.04710744\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.83192633\n",
      "Iteration 2, loss = 0.14410788\n",
      "Iteration 3, loss = 0.08771871\n",
      "Iteration 4, loss = 0.06670719\n",
      "Iteration 5, loss = 0.05764146\n",
      "Iteration 6, loss = 0.04902083\n",
      "Iteration 7, loss = 0.05438428\n",
      "Iteration 8, loss = 0.05569914\n",
      "Iteration 9, loss = 0.06604645\n",
      "Iteration 10, loss = 0.08006564\n",
      "Iteration 11, loss = 0.06160032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 0.05160623\n",
      "Iteration 13, loss = 0.04442408\n",
      "Iteration 14, loss = 0.06489635\n",
      "Iteration 15, loss = 0.06897609\n",
      "Iteration 16, loss = 0.06359454\n",
      "Iteration 17, loss = 0.05630063\n",
      "Iteration 18, loss = 0.05729456\n",
      "Iteration 19, loss = 0.04738473\n",
      "Iteration 20, loss = 0.04969624\n",
      "Iteration 21, loss = 0.04905646\n",
      "Iteration 22, loss = 0.04834780\n",
      "Iteration 23, loss = 0.04435482\n",
      "Iteration 24, loss = 0.04198128\n",
      "Iteration 25, loss = 0.06256937\n",
      "Iteration 26, loss = 0.06000882\n",
      "Iteration 27, loss = 0.05309616\n",
      "Iteration 28, loss = 0.05111301\n",
      "Iteration 29, loss = 0.05097258\n",
      "Iteration 30, loss = 0.05125244\n",
      "Iteration 31, loss = 0.04981795\n",
      "Iteration 32, loss = 0.04620977\n",
      "Iteration 33, loss = 0.04509723\n",
      "Iteration 34, loss = 0.04717613\n",
      "Iteration 35, loss = 0.05178338\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.83362918\n",
      "Iteration 2, loss = 0.14692378\n",
      "Iteration 3, loss = 0.09953879\n",
      "Iteration 4, loss = 0.08111109\n",
      "Iteration 5, loss = 0.06768684\n",
      "Iteration 6, loss = 0.05778249\n",
      "Iteration 7, loss = 0.05380810\n",
      "Iteration 8, loss = 0.05615430\n",
      "Iteration 9, loss = 0.04910993\n",
      "Iteration 10, loss = 0.04754566\n",
      "Iteration 11, loss = 0.04452942\n",
      "Iteration 12, loss = 0.05191184\n",
      "Iteration 13, loss = 0.04378722\n",
      "Iteration 14, loss = 0.05115355\n",
      "Iteration 15, loss = 0.04265413\n",
      "Iteration 16, loss = 0.04388538\n",
      "Iteration 17, loss = 0.03998292\n",
      "Iteration 18, loss = 0.03733539\n",
      "Iteration 19, loss = 0.03623437\n",
      "Iteration 20, loss = 0.04361501\n",
      "Iteration 21, loss = 0.06206255\n",
      "Iteration 22, loss = 0.04835173\n",
      "Iteration 23, loss = 0.04334285\n",
      "Iteration 24, loss = 0.04052682\n",
      "Iteration 25, loss = 0.03949368\n",
      "Iteration 26, loss = 0.04047908\n",
      "Iteration 27, loss = 0.03982779\n",
      "Iteration 28, loss = 0.03919252\n",
      "Iteration 29, loss = 0.04011845\n",
      "Iteration 30, loss = 0.04753400\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.83658529\n",
      "Iteration 2, loss = 0.15116732\n",
      "Iteration 3, loss = 0.09045351\n",
      "Iteration 4, loss = 0.08423191\n",
      "Iteration 5, loss = 0.06241603\n",
      "Iteration 6, loss = 0.05363868\n",
      "Iteration 7, loss = 0.05235378\n",
      "Iteration 8, loss = 0.05574432\n",
      "Iteration 9, loss = 0.05702585\n",
      "Iteration 10, loss = 0.06294335\n",
      "Iteration 11, loss = 0.05042735\n",
      "Iteration 12, loss = 0.04664669\n",
      "Iteration 13, loss = 0.04370623\n",
      "Iteration 14, loss = 0.03760334\n",
      "Iteration 15, loss = 0.03795211\n",
      "Iteration 16, loss = 0.05691706\n",
      "Iteration 17, loss = 0.05139476\n",
      "Iteration 18, loss = 0.05355325\n",
      "Iteration 19, loss = 0.04996444\n",
      "Iteration 20, loss = 0.04880990\n",
      "Iteration 21, loss = 0.04888690\n",
      "Iteration 22, loss = 0.04546559\n",
      "Iteration 23, loss = 0.04371512\n",
      "Iteration 24, loss = 0.05743397\n",
      "Iteration 25, loss = 0.07008333\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.83806748\n",
      "Iteration 2, loss = 0.15531372\n",
      "Iteration 3, loss = 0.09263582\n",
      "Iteration 4, loss = 0.08068123\n",
      "Iteration 5, loss = 0.06523777\n",
      "Iteration 6, loss = 0.05753098\n",
      "Iteration 7, loss = 0.05235165\n",
      "Iteration 8, loss = 0.04608660\n",
      "Iteration 9, loss = 0.04236909\n",
      "Iteration 10, loss = 0.04008710\n",
      "Iteration 11, loss = 0.04687395\n",
      "Iteration 12, loss = 0.04508246\n",
      "Iteration 13, loss = 0.04212984\n",
      "Iteration 14, loss = 0.03968687\n",
      "Iteration 15, loss = 0.04859117\n",
      "Iteration 16, loss = 0.04821007\n",
      "Iteration 17, loss = 0.03870472\n",
      "Iteration 18, loss = 0.04541285\n",
      "Iteration 19, loss = 0.04199876\n",
      "Iteration 20, loss = 0.04865636\n",
      "Iteration 21, loss = 0.05026519\n",
      "Iteration 22, loss = 0.05910107\n",
      "Iteration 23, loss = 0.06245356\n",
      "Iteration 24, loss = 0.05448984\n",
      "Iteration 25, loss = 0.05022427\n",
      "Iteration 26, loss = 0.07749637\n",
      "Iteration 27, loss = 0.05819326\n",
      "Iteration 28, loss = 0.05381085\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.78920257\n",
      "Iteration 2, loss = 0.13050658\n",
      "Iteration 3, loss = 0.08258438\n",
      "Iteration 4, loss = 0.07877541\n",
      "Iteration 5, loss = 0.06698726\n",
      "Iteration 6, loss = 0.05496237\n",
      "Iteration 7, loss = 0.06108111\n",
      "Iteration 8, loss = 0.04859452\n",
      "Iteration 9, loss = 0.04421312\n",
      "Iteration 10, loss = 0.04462039\n",
      "Iteration 11, loss = 0.04345697\n",
      "Iteration 12, loss = 0.04912057\n",
      "Iteration 13, loss = 0.05277779\n",
      "Iteration 14, loss = 0.05717541\n",
      "Iteration 15, loss = 0.04254239\n",
      "Iteration 16, loss = 0.04351183\n",
      "Iteration 17, loss = 0.03901202\n",
      "Iteration 18, loss = 0.04750976\n",
      "Iteration 19, loss = 0.04981955\n",
      "Iteration 20, loss = 0.04514468\n",
      "Iteration 21, loss = 0.04061507\n",
      "Iteration 22, loss = 0.03990216\n",
      "Iteration 23, loss = 0.04422163\n",
      "Iteration 24, loss = 0.04371421\n",
      "Iteration 25, loss = 0.04473843\n",
      "Iteration 26, loss = 0.03863309\n",
      "Iteration 27, loss = 0.03960019\n",
      "Iteration 28, loss = 0.03672832\n",
      "Iteration 29, loss = 0.04255493\n",
      "Iteration 30, loss = 0.03668570\n",
      "Iteration 31, loss = 0.03576006\n",
      "Iteration 32, loss = 0.03421760\n",
      "Iteration 33, loss = 0.03505963\n",
      "Iteration 34, loss = 0.03403148\n",
      "Iteration 35, loss = 0.03497606\n",
      "Iteration 36, loss = 0.03446069\n",
      "Iteration 37, loss = 0.03320772\n",
      "Iteration 38, loss = 0.03317374\n",
      "Iteration 39, loss = 0.03283122\n",
      "Iteration 40, loss = 0.04029916\n",
      "Iteration 41, loss = 0.04208158\n",
      "Iteration 42, loss = 0.06011562\n",
      "Iteration 43, loss = 0.08175647\n",
      "Iteration 44, loss = 0.07734541\n",
      "Iteration 45, loss = 0.06873853\n",
      "Iteration 46, loss = 0.05908289\n",
      "Iteration 47, loss = 0.05402577\n",
      "Iteration 48, loss = 0.05025349\n",
      "Iteration 49, loss = 0.04590027\n",
      "Iteration 50, loss = 0.04544143\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.79505902\n",
      "Iteration 2, loss = 0.13593657\n",
      "Iteration 3, loss = 0.08533667\n",
      "Iteration 4, loss = 0.06602133\n",
      "Iteration 5, loss = 0.05227811\n",
      "Iteration 6, loss = 0.04856034\n",
      "Iteration 7, loss = 0.06136469\n",
      "Iteration 8, loss = 0.04361474\n",
      "Iteration 9, loss = 0.03857628\n",
      "Iteration 10, loss = 0.03728130\n",
      "Iteration 11, loss = 0.04232579\n",
      "Iteration 12, loss = 0.03974116\n",
      "Iteration 13, loss = 0.03648675\n",
      "Iteration 14, loss = 0.03772785\n",
      "Iteration 15, loss = 0.03711902\n",
      "Iteration 16, loss = 0.03254427\n",
      "Iteration 17, loss = 0.03173282\n",
      "Iteration 18, loss = 0.03380374\n",
      "Iteration 19, loss = 0.03757922\n",
      "Iteration 20, loss = 0.03374089\n",
      "Iteration 21, loss = 0.03129601\n",
      "Iteration 22, loss = 0.03043314\n",
      "Iteration 23, loss = 0.03391841\n",
      "Iteration 24, loss = 0.04104704\n",
      "Iteration 25, loss = 0.04504847\n",
      "Iteration 26, loss = 0.05561689\n",
      "Iteration 27, loss = 0.05614244\n",
      "Iteration 28, loss = 0.05162656\n",
      "Iteration 29, loss = 0.05099407\n",
      "Iteration 30, loss = 0.04996101\n",
      "Iteration 31, loss = 0.04355318\n",
      "Iteration 32, loss = 0.04121230\n",
      "Iteration 33, loss = 0.03853032\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.79248608\n",
      "Iteration 2, loss = 0.13696061\n",
      "Iteration 3, loss = 0.08709387\n",
      "Iteration 4, loss = 0.06660296\n",
      "Iteration 5, loss = 0.05535145\n",
      "Iteration 6, loss = 0.05114121\n",
      "Iteration 7, loss = 0.05944536\n",
      "Iteration 8, loss = 0.05039425\n",
      "Iteration 9, loss = 0.04998023\n",
      "Iteration 10, loss = 0.04419699\n",
      "Iteration 11, loss = 0.04226887\n",
      "Iteration 12, loss = 0.04084261\n",
      "Iteration 13, loss = 0.04020506\n",
      "Iteration 14, loss = 0.04014706\n",
      "Iteration 15, loss = 0.03645083\n",
      "Iteration 16, loss = 0.03869058\n",
      "Iteration 17, loss = 0.03746037\n",
      "Iteration 18, loss = 0.03784234\n",
      "Iteration 19, loss = 0.03476483\n",
      "Iteration 20, loss = 0.03934841\n",
      "Iteration 21, loss = 0.03862680\n",
      "Iteration 22, loss = 0.04224799\n",
      "Iteration 23, loss = 0.03683830\n",
      "Iteration 24, loss = 0.04714009\n",
      "Iteration 25, loss = 0.05344813\n",
      "Iteration 26, loss = 0.05715875\n",
      "Iteration 27, loss = 0.06014711\n",
      "Iteration 28, loss = 0.05978077\n",
      "Iteration 29, loss = 0.08476964\n",
      "Iteration 30, loss = 0.07664158\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.74781683\n",
      "Iteration 2, loss = 0.13071140\n",
      "Iteration 3, loss = 0.08209925\n",
      "Iteration 4, loss = 0.06426200\n",
      "Iteration 5, loss = 0.04775497\n",
      "Iteration 6, loss = 0.04803871\n",
      "Iteration 7, loss = 0.04310926\n",
      "Iteration 8, loss = 0.04623450\n",
      "Iteration 9, loss = 0.04103772\n",
      "Iteration 10, loss = 0.03941063\n",
      "Iteration 11, loss = 0.04536573\n",
      "Iteration 12, loss = 0.04273471\n",
      "Iteration 13, loss = 0.04109274\n",
      "Iteration 14, loss = 0.05221017\n",
      "Iteration 15, loss = 0.04940092\n",
      "Iteration 16, loss = 0.05128851\n",
      "Iteration 17, loss = 0.04765766\n",
      "Iteration 18, loss = 0.04032502\n",
      "Iteration 19, loss = 0.04138591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20, loss = 0.03888845\n",
      "Iteration 21, loss = 0.03713982\n",
      "Iteration 22, loss = 0.03360151\n",
      "Iteration 23, loss = 0.03281994\n",
      "Iteration 24, loss = 0.03361027\n",
      "Iteration 25, loss = 0.04341278\n",
      "Iteration 26, loss = 0.03907421\n",
      "Iteration 27, loss = 0.03670784\n",
      "Iteration 28, loss = 0.03744193\n",
      "Iteration 29, loss = 0.04115090\n",
      "Iteration 30, loss = 0.03785176\n",
      "Iteration 31, loss = 0.04508030\n",
      "Iteration 32, loss = 0.04048371\n",
      "Iteration 33, loss = 0.03784291\n",
      "Iteration 34, loss = 0.04403309\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.76333794\n",
      "Iteration 2, loss = 0.13457571\n",
      "Iteration 3, loss = 0.08492090\n",
      "Iteration 4, loss = 0.06869702\n",
      "Iteration 5, loss = 0.06021189\n",
      "Iteration 6, loss = 0.06429009\n",
      "Iteration 7, loss = 0.05205919\n",
      "Iteration 8, loss = 0.05489749\n",
      "Iteration 9, loss = 0.04831886\n",
      "Iteration 10, loss = 0.05146905\n",
      "Iteration 11, loss = 0.04913243\n",
      "Iteration 12, loss = 0.04971305\n",
      "Iteration 13, loss = 0.04596363\n",
      "Iteration 14, loss = 0.04781492\n",
      "Iteration 15, loss = 0.04198620\n",
      "Iteration 16, loss = 0.04092294\n",
      "Iteration 17, loss = 0.04060662\n",
      "Iteration 18, loss = 0.04166953\n",
      "Iteration 19, loss = 0.03906286\n",
      "Iteration 20, loss = 0.03803104\n",
      "Iteration 21, loss = 0.03659569\n",
      "Iteration 22, loss = 0.03630205\n",
      "Iteration 23, loss = 0.03785740\n",
      "Iteration 24, loss = 0.03632821\n",
      "Iteration 25, loss = 0.04929551\n",
      "Iteration 26, loss = 0.04787966\n",
      "Iteration 27, loss = 0.04432027\n",
      "Iteration 28, loss = 0.04430295\n",
      "Iteration 29, loss = 0.04665503\n",
      "Iteration 30, loss = 0.04315061\n",
      "Iteration 31, loss = 0.04465353\n",
      "Iteration 32, loss = 0.04349472\n",
      "Iteration 33, loss = 0.04207368\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.77806734\n",
      "Iteration 2, loss = 0.13345088\n",
      "Iteration 3, loss = 0.07925806\n",
      "Iteration 4, loss = 0.06499899\n",
      "Iteration 5, loss = 0.05153915\n",
      "Iteration 6, loss = 0.04892341\n",
      "Iteration 7, loss = 0.04159328\n",
      "Iteration 8, loss = 0.03906717\n",
      "Iteration 9, loss = 0.04042172\n",
      "Iteration 10, loss = 0.05294966\n",
      "Iteration 11, loss = 0.03966352\n",
      "Iteration 12, loss = 0.04531469\n",
      "Iteration 13, loss = 0.04543288\n",
      "Iteration 14, loss = 0.03967390\n",
      "Iteration 15, loss = 0.03469217\n",
      "Iteration 16, loss = 0.05692980\n",
      "Iteration 17, loss = 0.08138254\n",
      "Iteration 18, loss = 0.07314532\n",
      "Iteration 19, loss = 0.06237799\n",
      "Iteration 20, loss = 0.05487753\n",
      "Iteration 21, loss = 0.05313859\n",
      "Iteration 22, loss = 0.05207519\n",
      "Iteration 23, loss = 0.04889295\n",
      "Iteration 24, loss = 0.04909154\n",
      "Iteration 25, loss = 0.05618641\n",
      "Iteration 26, loss = 0.04970660\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80287867\n",
      "Iteration 2, loss = 0.14229004\n",
      "Iteration 3, loss = 0.09860343\n",
      "Iteration 4, loss = 0.06943058\n",
      "Iteration 5, loss = 0.06083472\n",
      "Iteration 6, loss = 0.05539711\n",
      "Iteration 7, loss = 0.04444570\n",
      "Iteration 8, loss = 0.04823601\n",
      "Iteration 9, loss = 0.04577858\n",
      "Iteration 10, loss = 0.04214864\n",
      "Iteration 11, loss = 0.03675322\n",
      "Iteration 12, loss = 0.03782680\n",
      "Iteration 13, loss = 0.04164020\n",
      "Iteration 14, loss = 0.03996772\n",
      "Iteration 15, loss = 0.04104641\n",
      "Iteration 16, loss = 0.03946883\n",
      "Iteration 17, loss = 0.04389123\n",
      "Iteration 18, loss = 0.04186293\n",
      "Iteration 19, loss = 0.03630989\n",
      "Iteration 20, loss = 0.03431071\n",
      "Iteration 21, loss = 0.03346059\n",
      "Iteration 22, loss = 0.03274516\n",
      "Iteration 23, loss = 0.03348674\n",
      "Iteration 24, loss = 0.04170012\n",
      "Iteration 25, loss = 0.04488604\n",
      "Iteration 26, loss = 0.03927029\n",
      "Iteration 27, loss = 0.03959926\n",
      "Iteration 28, loss = 0.04411071\n",
      "Iteration 29, loss = 0.07361982\n",
      "Iteration 30, loss = 0.08260138\n",
      "Iteration 31, loss = 0.06532803\n",
      "Iteration 32, loss = 0.05222746\n",
      "Iteration 33, loss = 0.06061633\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80196021\n",
      "Iteration 2, loss = 0.14174020\n",
      "Iteration 3, loss = 0.08492429\n",
      "Iteration 4, loss = 0.07453926\n",
      "Iteration 5, loss = 0.07333164\n",
      "Iteration 6, loss = 0.05913860\n",
      "Iteration 7, loss = 0.05072090\n",
      "Iteration 8, loss = 0.04242517\n",
      "Iteration 9, loss = 0.04296629\n",
      "Iteration 10, loss = 0.04907198\n",
      "Iteration 11, loss = 0.04287956\n",
      "Iteration 12, loss = 0.04241579\n",
      "Iteration 13, loss = 0.03755335\n",
      "Iteration 14, loss = 0.04314568\n",
      "Iteration 15, loss = 0.04004186\n",
      "Iteration 16, loss = 0.03912587\n",
      "Iteration 17, loss = 0.03631873\n",
      "Iteration 18, loss = 0.03661155\n",
      "Iteration 19, loss = 0.03682050\n",
      "Iteration 20, loss = 0.03600009\n",
      "Iteration 21, loss = 0.03983736\n",
      "Iteration 22, loss = 0.03509516\n",
      "Iteration 23, loss = 0.03370486\n",
      "Iteration 24, loss = 0.03205832\n",
      "Iteration 25, loss = 0.04707367\n",
      "Iteration 26, loss = 0.05069093\n",
      "Iteration 27, loss = 0.04688431\n",
      "Iteration 28, loss = 0.04948176\n",
      "Iteration 29, loss = 0.04636653\n",
      "Iteration 30, loss = 0.03840499\n",
      "Iteration 31, loss = 0.04125350\n",
      "Iteration 32, loss = 0.03679697\n",
      "Iteration 33, loss = 0.04729240\n",
      "Iteration 34, loss = 0.03753081\n",
      "Iteration 35, loss = 0.03529259\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.78100564\n",
      "Iteration 2, loss = 0.13359201\n",
      "Iteration 3, loss = 0.08278924\n",
      "Iteration 4, loss = 0.07931794\n",
      "Iteration 5, loss = 0.06688877\n",
      "Iteration 6, loss = 0.05649386\n",
      "Iteration 7, loss = 0.04992947\n",
      "Iteration 8, loss = 0.04490386\n",
      "Iteration 9, loss = 0.04470665\n",
      "Iteration 10, loss = 0.05032636\n",
      "Iteration 11, loss = 0.04307231\n",
      "Iteration 12, loss = 0.04064177\n",
      "Iteration 13, loss = 0.04085512\n",
      "Iteration 14, loss = 0.03887200\n",
      "Iteration 15, loss = 0.03879771\n",
      "Iteration 16, loss = 0.03838108\n",
      "Iteration 17, loss = 0.03709974\n",
      "Iteration 18, loss = 0.03815140\n",
      "Iteration 19, loss = 0.03542273\n",
      "Iteration 20, loss = 0.03433379\n",
      "Iteration 21, loss = 0.03273071\n",
      "Iteration 22, loss = 0.03202345\n",
      "Iteration 23, loss = 0.03163493\n",
      "Iteration 24, loss = 0.03010593\n",
      "Iteration 25, loss = 0.03093626\n",
      "Iteration 26, loss = 0.02961907\n",
      "Iteration 27, loss = 0.02982670\n",
      "Iteration 28, loss = 0.03025645\n",
      "Iteration 29, loss = 0.02894866\n",
      "Iteration 30, loss = 0.03006919\n",
      "Iteration 31, loss = 0.02832262\n",
      "Iteration 32, loss = 0.02955478\n",
      "Iteration 33, loss = 0.05710122\n",
      "Iteration 34, loss = 0.13784181\n",
      "Iteration 35, loss = 0.12524983\n",
      "Iteration 36, loss = 0.08719591\n",
      "Iteration 37, loss = 0.06405601\n",
      "Iteration 38, loss = 0.06415626\n",
      "Iteration 39, loss = 0.05992672\n",
      "Iteration 40, loss = 0.06293794\n",
      "Iteration 41, loss = 0.05233677\n",
      "Iteration 42, loss = 0.05035612\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.78894318\n",
      "Iteration 2, loss = 0.13667686\n",
      "Iteration 3, loss = 0.08236127\n",
      "Iteration 4, loss = 0.07023724\n",
      "Iteration 5, loss = 0.06736715\n",
      "Iteration 6, loss = 0.06140830\n",
      "Iteration 7, loss = 0.05017609\n",
      "Iteration 8, loss = 0.05095570\n",
      "Iteration 9, loss = 0.05664644\n",
      "Iteration 10, loss = 0.04829485\n",
      "Iteration 11, loss = 0.04544365\n",
      "Iteration 12, loss = 0.04363374\n",
      "Iteration 13, loss = 0.04100669\n",
      "Iteration 14, loss = 0.04900969\n",
      "Iteration 15, loss = 0.04546046\n",
      "Iteration 16, loss = 0.04365493\n",
      "Iteration 17, loss = 0.04386922\n",
      "Iteration 18, loss = 0.04556161\n",
      "Iteration 19, loss = 0.04160817\n",
      "Iteration 20, loss = 0.04408643\n",
      "Iteration 21, loss = 0.06182887\n",
      "Iteration 22, loss = 0.07647957\n",
      "Iteration 23, loss = 0.08220734\n",
      "Iteration 24, loss = 0.07402693\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.72096116\n",
      "Iteration 2, loss = 0.11883512\n",
      "Iteration 3, loss = 0.07749952\n",
      "Iteration 4, loss = 0.07019535\n",
      "Iteration 5, loss = 0.05888428\n",
      "Iteration 6, loss = 0.04862207\n",
      "Iteration 7, loss = 0.04684159\n",
      "Iteration 8, loss = 0.04134517\n",
      "Iteration 9, loss = 0.03888546\n",
      "Iteration 10, loss = 0.03772932\n",
      "Iteration 11, loss = 0.03930407\n",
      "Iteration 12, loss = 0.03946049\n",
      "Iteration 13, loss = 0.03928371\n",
      "Iteration 14, loss = 0.03977496\n",
      "Iteration 15, loss = 0.04188748\n",
      "Iteration 16, loss = 0.04540528\n",
      "Iteration 17, loss = 0.04868704\n",
      "Iteration 18, loss = 0.04247435\n",
      "Iteration 19, loss = 0.04537118\n",
      "Iteration 20, loss = 0.04424839\n",
      "Iteration 21, loss = 0.04690580\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.72123102\n",
      "Iteration 2, loss = 0.12065033\n",
      "Iteration 3, loss = 0.07542679\n",
      "Iteration 4, loss = 0.05895522\n",
      "Iteration 5, loss = 0.05022024\n",
      "Iteration 6, loss = 0.04398982\n",
      "Iteration 7, loss = 0.03957826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 0.04436293\n",
      "Iteration 9, loss = 0.04131382\n",
      "Iteration 10, loss = 0.05892366\n",
      "Iteration 11, loss = 0.04258594\n",
      "Iteration 12, loss = 0.03884751\n",
      "Iteration 13, loss = 0.03993439\n",
      "Iteration 14, loss = 0.04608159\n",
      "Iteration 15, loss = 0.04470529\n",
      "Iteration 16, loss = 0.04800165\n",
      "Iteration 17, loss = 0.04305810\n",
      "Iteration 18, loss = 0.04026201\n",
      "Iteration 19, loss = 0.04752954\n",
      "Iteration 20, loss = 0.04608738\n",
      "Iteration 21, loss = 0.04431497\n",
      "Iteration 22, loss = 0.03900029\n",
      "Iteration 23, loss = 0.06242154\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.72605527\n",
      "Iteration 2, loss = 0.11671198\n",
      "Iteration 3, loss = 0.07547079\n",
      "Iteration 4, loss = 0.06184577\n",
      "Iteration 5, loss = 0.05407842\n",
      "Iteration 6, loss = 0.05588212\n",
      "Iteration 7, loss = 0.05056861\n",
      "Iteration 8, loss = 0.04777918\n",
      "Iteration 9, loss = 0.04857382\n",
      "Iteration 10, loss = 0.04636724\n",
      "Iteration 11, loss = 0.04115275\n",
      "Iteration 12, loss = 0.03577167\n",
      "Iteration 13, loss = 0.03424322\n",
      "Iteration 14, loss = 0.03346394\n",
      "Iteration 15, loss = 0.03504313\n",
      "Iteration 16, loss = 0.03590198\n",
      "Iteration 17, loss = 0.04037893\n",
      "Iteration 18, loss = 0.04646945\n",
      "Iteration 19, loss = 0.04252522\n",
      "Iteration 20, loss = 0.05081042\n",
      "Iteration 21, loss = 0.05551825\n",
      "Iteration 22, loss = 0.06950169\n",
      "Iteration 23, loss = 0.08583682\n",
      "Iteration 24, loss = 0.05964719\n",
      "Iteration 25, loss = 0.05192900\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.70031045\n",
      "Iteration 2, loss = 0.11627951\n",
      "Iteration 3, loss = 0.07575523\n",
      "Iteration 4, loss = 0.05927691\n",
      "Iteration 5, loss = 0.05390541\n",
      "Iteration 6, loss = 0.04771956\n",
      "Iteration 7, loss = 0.04133433\n",
      "Iteration 8, loss = 0.04920661\n",
      "Iteration 9, loss = 0.05050158\n",
      "Iteration 10, loss = 0.05798770\n",
      "Iteration 11, loss = 0.04869680\n",
      "Iteration 12, loss = 0.04711358\n",
      "Iteration 13, loss = 0.04239966\n",
      "Iteration 14, loss = 0.04202937\n",
      "Iteration 15, loss = 0.03997346\n",
      "Iteration 16, loss = 0.04246704\n",
      "Iteration 17, loss = 0.04777216\n",
      "Iteration 18, loss = 0.04868334\n",
      "Iteration 19, loss = 0.04658795\n",
      "Iteration 20, loss = 0.05365349\n",
      "Iteration 21, loss = 0.04027937\n",
      "Iteration 22, loss = 0.04366797\n",
      "Iteration 23, loss = 0.04553156\n",
      "Iteration 24, loss = 0.04303138\n",
      "Iteration 25, loss = 0.03915944\n",
      "Iteration 26, loss = 0.04556003\n",
      "Iteration 27, loss = 0.05100023\n",
      "Iteration 28, loss = 0.05491917\n",
      "Iteration 29, loss = 0.05833741\n",
      "Iteration 30, loss = 0.05124128\n",
      "Iteration 31, loss = 0.04806169\n",
      "Iteration 32, loss = 0.04526642\n",
      "Iteration 33, loss = 0.03943444\n",
      "Iteration 34, loss = 0.03702508\n",
      "Iteration 35, loss = 0.03789612\n",
      "Iteration 36, loss = 0.04321210\n",
      "Iteration 37, loss = 0.04252019\n",
      "Iteration 38, loss = 0.04007132\n",
      "Iteration 39, loss = 0.04045515\n",
      "Iteration 40, loss = 0.03887301\n",
      "Iteration 41, loss = 0.03509652\n",
      "Iteration 42, loss = 0.03905855\n",
      "Iteration 43, loss = 0.03671282\n",
      "Iteration 44, loss = 0.03625374\n",
      "Iteration 45, loss = 0.04652204\n",
      "Iteration 46, loss = 0.03880974\n",
      "Iteration 47, loss = 0.03625816\n",
      "Iteration 48, loss = 0.03444072\n",
      "Iteration 49, loss = 0.03438162\n",
      "Iteration 50, loss = 0.03325944\n",
      "Iteration 51, loss = 0.03459513\n",
      "Iteration 52, loss = 0.07665360\n",
      "Iteration 53, loss = 0.07242070\n",
      "Iteration 54, loss = 0.07915407\n",
      "Iteration 55, loss = 0.07404875\n",
      "Iteration 56, loss = 0.06378638\n",
      "Iteration 57, loss = 0.05768101\n",
      "Iteration 58, loss = 0.05516341\n",
      "Iteration 59, loss = 0.05541550\n",
      "Iteration 60, loss = 0.05030751\n",
      "Iteration 61, loss = 0.04944094\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.70541655\n",
      "Iteration 2, loss = 0.12058399\n",
      "Iteration 3, loss = 0.08405255\n",
      "Iteration 4, loss = 0.06002333\n",
      "Iteration 5, loss = 0.04913976\n",
      "Iteration 6, loss = 0.04518550\n",
      "Iteration 7, loss = 0.04346098\n",
      "Iteration 8, loss = 0.04296248\n",
      "Iteration 9, loss = 0.04259250\n",
      "Iteration 10, loss = 0.04026482\n",
      "Iteration 11, loss = 0.03862239\n",
      "Iteration 12, loss = 0.03611826\n",
      "Iteration 13, loss = 0.03419235\n",
      "Iteration 14, loss = 0.03504050\n",
      "Iteration 15, loss = 0.03972576\n",
      "Iteration 16, loss = 0.04763715\n",
      "Iteration 17, loss = 0.04582369\n",
      "Iteration 18, loss = 0.04461211\n",
      "Iteration 19, loss = 0.04755949\n",
      "Iteration 20, loss = 0.06040942\n",
      "Iteration 21, loss = 0.07635777\n",
      "Iteration 22, loss = 0.07680372\n",
      "Iteration 23, loss = 0.06650800\n",
      "Iteration 24, loss = 0.05288908\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.69655547\n",
      "Iteration 2, loss = 0.10759302\n",
      "Iteration 3, loss = 0.06472250\n",
      "Iteration 4, loss = 0.05608756\n",
      "Iteration 5, loss = 0.04828754\n",
      "Iteration 6, loss = 0.04381301\n",
      "Iteration 7, loss = 0.04300301\n",
      "Iteration 8, loss = 0.03947689\n",
      "Iteration 9, loss = 0.04030113\n",
      "Iteration 10, loss = 0.03773996\n",
      "Iteration 11, loss = 0.03533277\n",
      "Iteration 12, loss = 0.03720730\n",
      "Iteration 13, loss = 0.04513996\n",
      "Iteration 14, loss = 0.05372840\n",
      "Iteration 15, loss = 0.05030060\n",
      "Iteration 16, loss = 0.06199055\n",
      "Iteration 17, loss = 0.05759536\n",
      "Iteration 18, loss = 0.05349230\n",
      "Iteration 19, loss = 0.05102411\n",
      "Iteration 20, loss = 0.04741464\n",
      "Iteration 21, loss = 0.05391614\n",
      "Iteration 22, loss = 0.04681803\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.69476090\n",
      "Iteration 2, loss = 0.11240099\n",
      "Iteration 3, loss = 0.07189954\n",
      "Iteration 4, loss = 0.05814139\n",
      "Iteration 5, loss = 0.05320194\n",
      "Iteration 6, loss = 0.04929319\n",
      "Iteration 7, loss = 0.04964722\n",
      "Iteration 8, loss = 0.05077432\n",
      "Iteration 9, loss = 0.04673738\n",
      "Iteration 10, loss = 0.04349163\n",
      "Iteration 11, loss = 0.03840793\n",
      "Iteration 12, loss = 0.04065965\n",
      "Iteration 13, loss = 0.03778064\n",
      "Iteration 14, loss = 0.03797892\n",
      "Iteration 15, loss = 0.03564750\n",
      "Iteration 16, loss = 0.04385389\n",
      "Iteration 17, loss = 0.05154481\n",
      "Iteration 18, loss = 0.04468773\n",
      "Iteration 19, loss = 0.04493517\n",
      "Iteration 20, loss = 0.04522942\n",
      "Iteration 21, loss = 0.04350890\n",
      "Iteration 22, loss = 0.03569676\n",
      "Iteration 23, loss = 0.03545157\n",
      "Iteration 24, loss = 0.03959983\n",
      "Iteration 25, loss = 0.03443681\n",
      "Iteration 26, loss = 0.03979835\n",
      "Iteration 27, loss = 0.03683728\n",
      "Iteration 28, loss = 0.03245949\n",
      "Iteration 29, loss = 0.03134296\n",
      "Iteration 30, loss = 0.03123335\n",
      "Iteration 31, loss = 0.03185328\n",
      "Iteration 32, loss = 0.03324187\n",
      "Iteration 33, loss = 0.02995491\n",
      "Iteration 34, loss = 0.02939606\n",
      "Iteration 35, loss = 0.02724990\n",
      "Iteration 36, loss = 0.02830247\n",
      "Iteration 37, loss = 0.02833906\n",
      "Iteration 38, loss = 0.02821643\n",
      "Iteration 39, loss = 0.02750492\n",
      "Iteration 40, loss = 0.02734112\n",
      "Iteration 41, loss = 0.02786472\n",
      "Iteration 42, loss = 0.02689537\n",
      "Iteration 43, loss = 0.02737988\n",
      "Iteration 44, loss = 0.02637137\n",
      "Iteration 45, loss = 0.06443780\n",
      "Iteration 46, loss = 0.11186073\n",
      "Iteration 47, loss = 0.12705427\n",
      "Iteration 48, loss = 0.09672194\n",
      "Iteration 49, loss = 0.07927253\n",
      "Iteration 50, loss = 0.07310908\n",
      "Iteration 51, loss = 0.06228268\n",
      "Iteration 52, loss = 0.06759703\n",
      "Iteration 53, loss = 0.06261013\n",
      "Iteration 54, loss = 0.06211391\n",
      "Iteration 55, loss = 0.05389037\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.70545638\n",
      "Iteration 2, loss = 0.11650798\n",
      "Iteration 3, loss = 0.07526211\n",
      "Iteration 4, loss = 0.06177826\n",
      "Iteration 5, loss = 0.05234278\n",
      "Iteration 6, loss = 0.04552099\n",
      "Iteration 7, loss = 0.04343538\n",
      "Iteration 8, loss = 0.04069730\n",
      "Iteration 9, loss = 0.03923956\n",
      "Iteration 10, loss = 0.03799472\n",
      "Iteration 11, loss = 0.03962989\n",
      "Iteration 12, loss = 0.04244757\n",
      "Iteration 13, loss = 0.03831535\n",
      "Iteration 14, loss = 0.03844318\n",
      "Iteration 15, loss = 0.03914144\n",
      "Iteration 16, loss = 0.04024160\n",
      "Iteration 17, loss = 0.06853177\n",
      "Iteration 18, loss = 0.05907477\n",
      "Iteration 19, loss = 0.05153409\n",
      "Iteration 20, loss = 0.05419402\n",
      "Iteration 21, loss = 0.06424589\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.70574398\n",
      "Iteration 2, loss = 0.11497534\n",
      "Iteration 3, loss = 0.06981777\n",
      "Iteration 4, loss = 0.05861955\n",
      "Iteration 5, loss = 0.04597258\n",
      "Iteration 6, loss = 0.04572848\n",
      "Iteration 7, loss = 0.03975527\n",
      "Iteration 8, loss = 0.03853617\n",
      "Iteration 9, loss = 0.03520157\n",
      "Iteration 10, loss = 0.03395498\n",
      "Iteration 11, loss = 0.03900738\n",
      "Iteration 12, loss = 0.03669606\n",
      "Iteration 13, loss = 0.04223101\n",
      "Iteration 14, loss = 0.04205622\n",
      "Iteration 15, loss = 0.04256027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 16, loss = 0.05413379\n",
      "Iteration 17, loss = 0.06525587\n",
      "Iteration 18, loss = 0.05853246\n",
      "Iteration 19, loss = 0.05709870\n",
      "Iteration 20, loss = 0.06670781\n",
      "Iteration 21, loss = 0.07485096\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.73061058\n",
      "Iteration 2, loss = 0.11653193\n",
      "Iteration 3, loss = 0.07320098\n",
      "Iteration 4, loss = 0.06151838\n",
      "Iteration 5, loss = 0.05655710\n",
      "Iteration 6, loss = 0.04859338\n",
      "Iteration 7, loss = 0.04336973\n",
      "Iteration 8, loss = 0.03981431\n",
      "Iteration 9, loss = 0.04086843\n",
      "Iteration 10, loss = 0.03937378\n",
      "Iteration 11, loss = 0.03773232\n",
      "Iteration 12, loss = 0.04243816\n",
      "Iteration 13, loss = 0.03953486\n",
      "Iteration 14, loss = 0.03513705\n",
      "Iteration 15, loss = 0.03392772\n",
      "Iteration 16, loss = 0.03362581\n",
      "Iteration 17, loss = 0.07571253\n",
      "Iteration 18, loss = 0.08612544\n",
      "Iteration 19, loss = 0.06831010\n",
      "Iteration 20, loss = 0.08091791\n",
      "Iteration 21, loss = 0.06488180\n",
      "Iteration 22, loss = 0.07682223\n",
      "Iteration 23, loss = 0.06740209\n",
      "Iteration 24, loss = 0.05368840\n",
      "Iteration 25, loss = 0.04788346\n",
      "Iteration 26, loss = 0.04803221\n",
      "Iteration 27, loss = 0.04862836\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.68985202\n",
      "Iteration 2, loss = 0.12463710\n",
      "Iteration 3, loss = 0.08947562\n",
      "Iteration 4, loss = 0.06746575\n",
      "Iteration 5, loss = 0.06847208\n",
      "Iteration 6, loss = 0.05801376\n",
      "Iteration 7, loss = 0.05524929\n",
      "Iteration 8, loss = 0.04634968\n",
      "Iteration 9, loss = 0.04037628\n",
      "Iteration 10, loss = 0.03941855\n",
      "Iteration 11, loss = 0.03714062\n",
      "Iteration 12, loss = 0.03752576\n",
      "Iteration 13, loss = 0.03407528\n",
      "Iteration 14, loss = 0.03306794\n",
      "Iteration 15, loss = 0.03426421\n",
      "Iteration 16, loss = 0.03521180\n",
      "Iteration 17, loss = 0.03662669\n",
      "Iteration 18, loss = 0.05492361\n",
      "Iteration 19, loss = 0.06859316\n",
      "Iteration 20, loss = 0.06003209\n",
      "Iteration 21, loss = 0.06128738\n",
      "Iteration 22, loss = 0.05057596\n",
      "Iteration 23, loss = 0.04854017\n",
      "Iteration 24, loss = 0.03983656\n",
      "Iteration 25, loss = 0.04058991\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.69300477\n",
      "Iteration 2, loss = 0.12340913\n",
      "Iteration 3, loss = 0.08237825\n",
      "Iteration 4, loss = 0.05909685\n",
      "Iteration 5, loss = 0.05798715\n",
      "Iteration 6, loss = 0.05654247\n",
      "Iteration 7, loss = 0.04708601\n",
      "Iteration 8, loss = 0.04308809\n",
      "Iteration 9, loss = 0.03966520\n",
      "Iteration 10, loss = 0.04081826\n",
      "Iteration 11, loss = 0.03924125\n",
      "Iteration 12, loss = 0.04547643\n",
      "Iteration 13, loss = 0.04220503\n",
      "Iteration 14, loss = 0.03801206\n",
      "Iteration 15, loss = 0.04060203\n",
      "Iteration 16, loss = 0.04066507\n",
      "Iteration 17, loss = 0.04513515\n",
      "Iteration 18, loss = 0.06417529\n",
      "Iteration 19, loss = 0.04650111\n",
      "Iteration 20, loss = 0.04354180\n",
      "Iteration 21, loss = 0.04114149\n",
      "Iteration 22, loss = 0.04095317\n",
      "Iteration 23, loss = 0.03508916\n",
      "Iteration 24, loss = 0.03262581\n",
      "Iteration 25, loss = 0.03283823\n",
      "Iteration 26, loss = 0.03490843\n",
      "Iteration 27, loss = 0.03621218\n",
      "Iteration 28, loss = 0.05270624\n",
      "Iteration 29, loss = 0.04225707\n",
      "Iteration 30, loss = 0.06411319\n",
      "Iteration 31, loss = 0.08387883\n",
      "Iteration 32, loss = 0.08191420\n",
      "Iteration 33, loss = 0.07597940\n",
      "Iteration 34, loss = 0.06183440\n",
      "Iteration 35, loss = 0.06692904\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.67789427\n",
      "Iteration 2, loss = 0.11621575\n",
      "Iteration 3, loss = 0.09003004\n",
      "Iteration 4, loss = 0.06321957\n",
      "Iteration 5, loss = 0.05952091\n",
      "Iteration 6, loss = 0.04936788\n",
      "Iteration 7, loss = 0.04381182\n",
      "Iteration 8, loss = 0.04272515\n",
      "Iteration 9, loss = 0.03619370\n",
      "Iteration 10, loss = 0.03564824\n",
      "Iteration 11, loss = 0.03527277\n",
      "Iteration 12, loss = 0.03445705\n",
      "Iteration 13, loss = 0.03564886\n",
      "Iteration 14, loss = 0.03618519\n",
      "Iteration 15, loss = 0.05121542\n",
      "Iteration 16, loss = 0.04727423\n",
      "Iteration 17, loss = 0.04734284\n",
      "Iteration 18, loss = 0.07235956\n",
      "Iteration 19, loss = 0.06468313\n",
      "Iteration 20, loss = 0.04933870\n",
      "Iteration 21, loss = 0.04794405\n",
      "Iteration 22, loss = 0.04720087\n",
      "Iteration 23, loss = 0.04391195\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.72054266\n",
      "Iteration 2, loss = 0.12143358\n",
      "Iteration 3, loss = 0.08469549\n",
      "Iteration 4, loss = 0.06764736\n",
      "Iteration 5, loss = 0.05945477\n",
      "Iteration 6, loss = 0.06438778\n",
      "Iteration 7, loss = 0.05412915\n",
      "Iteration 8, loss = 0.04265657\n",
      "Iteration 9, loss = 0.04113102\n",
      "Iteration 10, loss = 0.04183074\n",
      "Iteration 11, loss = 0.03982529\n",
      "Iteration 12, loss = 0.03593327\n",
      "Iteration 13, loss = 0.03432712\n",
      "Iteration 14, loss = 0.03420175\n",
      "Iteration 15, loss = 0.03309314\n",
      "Iteration 16, loss = 0.03728824\n",
      "Iteration 17, loss = 0.03378202\n",
      "Iteration 18, loss = 0.03134024\n",
      "Iteration 19, loss = 0.03217397\n",
      "Iteration 20, loss = 0.03129249\n",
      "Iteration 21, loss = 0.03252223\n",
      "Iteration 22, loss = 0.03260241\n",
      "Iteration 23, loss = 0.03766225\n",
      "Iteration 24, loss = 0.04260205\n",
      "Iteration 25, loss = 0.06880950\n",
      "Iteration 26, loss = 0.08665325\n",
      "Iteration 27, loss = 0.07811494\n",
      "Iteration 28, loss = 0.11135766\n",
      "Iteration 29, loss = 0.10758649\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.71707952\n",
      "Iteration 2, loss = 0.11667522\n",
      "Iteration 3, loss = 0.07970427\n",
      "Iteration 4, loss = 0.06333403\n",
      "Iteration 5, loss = 0.06050661\n",
      "Iteration 6, loss = 0.05677074\n",
      "Iteration 7, loss = 0.05031764\n",
      "Iteration 8, loss = 0.04775905\n",
      "Iteration 9, loss = 0.04308783\n",
      "Iteration 10, loss = 0.04091456\n",
      "Iteration 11, loss = 0.04235026\n",
      "Iteration 12, loss = 0.04165167\n",
      "Iteration 13, loss = 0.04668460\n",
      "Iteration 14, loss = 0.04272142\n",
      "Iteration 15, loss = 0.03888145\n",
      "Iteration 16, loss = 0.04379545\n",
      "Iteration 17, loss = 0.03824168\n",
      "Iteration 18, loss = 0.04440074\n",
      "Iteration 19, loss = 0.05102735\n",
      "Iteration 20, loss = 0.05724729\n",
      "Iteration 21, loss = 0.06194407\n",
      "Iteration 22, loss = 0.06118239\n",
      "Iteration 23, loss = 0.05379278\n",
      "Iteration 24, loss = 0.05152431\n",
      "Iteration 25, loss = 0.04693406\n",
      "Iteration 26, loss = 0.04850407\n",
      "Iteration 27, loss = 0.04301583\n",
      "Iteration 28, loss = 0.04008799\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.71870765\n",
      "Iteration 2, loss = 0.11658704\n",
      "Iteration 3, loss = 0.07779191\n",
      "Iteration 4, loss = 0.05692412\n",
      "Iteration 5, loss = 0.05773670\n",
      "Iteration 6, loss = 0.05381513\n",
      "Iteration 7, loss = 0.04868800\n",
      "Iteration 8, loss = 0.03849056\n",
      "Iteration 9, loss = 0.03579436\n",
      "Iteration 10, loss = 0.03315367\n",
      "Iteration 11, loss = 0.03695189\n",
      "Iteration 12, loss = 0.03393329\n",
      "Iteration 13, loss = 0.03353451\n",
      "Iteration 14, loss = 0.03028861\n",
      "Iteration 15, loss = 0.02868774\n",
      "Iteration 16, loss = 0.02703044\n",
      "Iteration 17, loss = 0.02642547\n",
      "Iteration 18, loss = 0.02638742\n",
      "Iteration 19, loss = 0.02834058\n",
      "Iteration 20, loss = 0.02946551\n",
      "Iteration 21, loss = 0.03954616\n",
      "Iteration 22, loss = 0.03439205\n",
      "Iteration 23, loss = 0.03274461\n",
      "Iteration 24, loss = 0.03275540\n",
      "Iteration 25, loss = 0.03726154\n",
      "Iteration 26, loss = 0.03756908\n",
      "Iteration 27, loss = 0.03811091\n",
      "Iteration 28, loss = 0.12250168\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.70682912\n",
      "Iteration 2, loss = 0.11307515\n",
      "Iteration 3, loss = 0.07338378\n",
      "Iteration 4, loss = 0.05313128\n",
      "Iteration 5, loss = 0.04929269\n",
      "Iteration 6, loss = 0.05242248\n",
      "Iteration 7, loss = 0.04805960\n",
      "Iteration 8, loss = 0.04104680\n",
      "Iteration 9, loss = 0.03582696\n",
      "Iteration 10, loss = 0.03636018\n",
      "Iteration 11, loss = 0.03697281\n",
      "Iteration 12, loss = 0.03251627\n",
      "Iteration 13, loss = 0.03302455\n",
      "Iteration 14, loss = 0.03160900\n",
      "Iteration 15, loss = 0.03066427\n",
      "Iteration 16, loss = 0.03456791\n",
      "Iteration 17, loss = 0.03319727\n",
      "Iteration 18, loss = 0.03212484\n",
      "Iteration 19, loss = 0.04588571\n",
      "Iteration 20, loss = 0.04407675\n",
      "Iteration 21, loss = 0.07123870\n",
      "Iteration 22, loss = 0.06457862\n",
      "Iteration 23, loss = 0.05429063\n",
      "Iteration 24, loss = 0.05090426\n",
      "Iteration 25, loss = 0.04903547\n",
      "Iteration 26, loss = 0.04410136\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.70185245\n",
      "Iteration 2, loss = 0.11732559\n",
      "Iteration 3, loss = 0.07422037\n",
      "Iteration 4, loss = 0.05924128\n",
      "Iteration 5, loss = 0.04981795\n",
      "Iteration 6, loss = 0.05413178\n",
      "Iteration 7, loss = 0.04683067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 0.04377539\n",
      "Iteration 9, loss = 0.04389786\n",
      "Iteration 10, loss = 0.04005574\n",
      "Iteration 11, loss = 0.03849996\n",
      "Iteration 12, loss = 0.03576349\n",
      "Iteration 13, loss = 0.03716584\n",
      "Iteration 14, loss = 0.03659748\n",
      "Iteration 15, loss = 0.03523899\n",
      "Iteration 16, loss = 0.03669819\n",
      "Iteration 17, loss = 0.04522400\n",
      "Iteration 18, loss = 0.04545284\n",
      "Iteration 19, loss = 0.05897827\n",
      "Iteration 20, loss = 0.06320097\n",
      "Iteration 21, loss = 0.10881416\n",
      "Iteration 22, loss = 0.07957914\n",
      "Iteration 23, loss = 0.09360563\n",
      "Iteration 24, loss = 0.07435930\n",
      "Iteration 25, loss = 0.06263744\n",
      "Iteration 26, loss = 0.05754365\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.69175156\n",
      "Iteration 2, loss = 0.11694766\n",
      "Iteration 3, loss = 0.07583405\n",
      "Iteration 4, loss = 0.05991185\n",
      "Iteration 5, loss = 0.05459550\n",
      "Iteration 6, loss = 0.04811814\n",
      "Iteration 7, loss = 0.04603221\n",
      "Iteration 8, loss = 0.04718044\n",
      "Iteration 9, loss = 0.04573868\n",
      "Iteration 10, loss = 0.03805035\n",
      "Iteration 11, loss = 0.03906918\n",
      "Iteration 12, loss = 0.03356204\n",
      "Iteration 13, loss = 0.03271422\n",
      "Iteration 14, loss = 0.03339632\n",
      "Iteration 15, loss = 0.03838039\n",
      "Iteration 16, loss = 0.03690651\n",
      "Iteration 17, loss = 0.04476433\n",
      "Iteration 18, loss = 0.06333404\n",
      "Iteration 19, loss = 0.08006917\n",
      "Iteration 20, loss = 0.09566207\n",
      "Iteration 21, loss = 0.09979063\n",
      "Iteration 22, loss = 0.07061431\n",
      "Iteration 23, loss = 0.05446331\n",
      "Iteration 24, loss = 0.04876168\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.66735823\n",
      "Iteration 2, loss = 0.10917900\n",
      "Iteration 3, loss = 0.08282300\n",
      "Iteration 4, loss = 0.05873251\n",
      "Iteration 5, loss = 0.05476850\n",
      "Iteration 6, loss = 0.05193297\n",
      "Iteration 7, loss = 0.04348027\n",
      "Iteration 8, loss = 0.04115096\n",
      "Iteration 9, loss = 0.03891195\n",
      "Iteration 10, loss = 0.03766227\n",
      "Iteration 11, loss = 0.03716553\n",
      "Iteration 12, loss = 0.03445460\n",
      "Iteration 13, loss = 0.03647022\n",
      "Iteration 14, loss = 0.03353714\n",
      "Iteration 15, loss = 0.03285828\n",
      "Iteration 16, loss = 0.03531759\n",
      "Iteration 17, loss = 0.03597821\n",
      "Iteration 18, loss = 0.04926453\n",
      "Iteration 19, loss = 0.04353633\n",
      "Iteration 20, loss = 0.04259588\n",
      "Iteration 21, loss = 0.06530298\n",
      "Iteration 22, loss = 0.06076862\n",
      "Iteration 23, loss = 0.05466070\n",
      "Iteration 24, loss = 0.05250199\n",
      "Iteration 25, loss = 0.04770947\n",
      "Iteration 26, loss = 0.05262340\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.71284987\n",
      "Iteration 2, loss = 0.11208752\n",
      "Iteration 3, loss = 0.06750503\n",
      "Iteration 4, loss = 0.05544600\n",
      "Iteration 5, loss = 0.04932731\n",
      "Iteration 6, loss = 0.05781632\n",
      "Iteration 7, loss = 0.05125683\n",
      "Iteration 8, loss = 0.05136947\n",
      "Iteration 9, loss = 0.04287841\n",
      "Iteration 10, loss = 0.04239381\n",
      "Iteration 11, loss = 0.04773686\n",
      "Iteration 12, loss = 0.05100292\n",
      "Iteration 13, loss = 0.04388448\n",
      "Iteration 14, loss = 0.04010065\n",
      "Iteration 15, loss = 0.04820081\n",
      "Iteration 16, loss = 0.05622192\n",
      "Iteration 17, loss = 0.05316166\n",
      "Iteration 18, loss = 0.04652962\n",
      "Iteration 19, loss = 0.04277416\n",
      "Iteration 20, loss = 0.03871664\n",
      "Iteration 21, loss = 0.03823395\n",
      "Iteration 22, loss = 0.03746386\n",
      "Iteration 23, loss = 0.04120190\n",
      "Iteration 24, loss = 0.03771578\n",
      "Iteration 25, loss = 0.04443093\n",
      "Iteration 26, loss = 0.04176082\n",
      "Iteration 27, loss = 0.04626097\n",
      "Iteration 28, loss = 0.04500070\n",
      "Iteration 29, loss = 0.04536699\n",
      "Iteration 30, loss = 0.04489217\n",
      "Iteration 31, loss = 0.03946511\n",
      "Iteration 32, loss = 0.03780516\n",
      "Iteration 33, loss = 0.03863563\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.72274520\n",
      "Iteration 2, loss = 0.11582293\n",
      "Iteration 3, loss = 0.06698990\n",
      "Iteration 4, loss = 0.05671506\n",
      "Iteration 5, loss = 0.05006667\n",
      "Iteration 6, loss = 0.04662366\n",
      "Iteration 7, loss = 0.04258121\n",
      "Iteration 8, loss = 0.04150086\n",
      "Iteration 9, loss = 0.03848296\n",
      "Iteration 10, loss = 0.03676382\n",
      "Iteration 11, loss = 0.04674688\n",
      "Iteration 12, loss = 0.04204270\n",
      "Iteration 13, loss = 0.04231847\n",
      "Iteration 14, loss = 0.04120876\n",
      "Iteration 15, loss = 0.04504851\n",
      "Iteration 16, loss = 0.04119541\n",
      "Iteration 17, loss = 0.04637045\n",
      "Iteration 18, loss = 0.04555937\n",
      "Iteration 19, loss = 0.04397303\n",
      "Iteration 20, loss = 0.04071826\n",
      "Iteration 21, loss = 0.04913555\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.63817518\n",
      "Iteration 2, loss = 0.10877961\n",
      "Iteration 3, loss = 0.07023525\n",
      "Iteration 4, loss = 0.05369384\n",
      "Iteration 5, loss = 0.04876262\n",
      "Iteration 6, loss = 0.04520079\n",
      "Iteration 7, loss = 0.04427235\n",
      "Iteration 8, loss = 0.04030838\n",
      "Iteration 9, loss = 0.03815967\n",
      "Iteration 10, loss = 0.04314167\n",
      "Iteration 11, loss = 0.04670089\n",
      "Iteration 12, loss = 0.04704409\n",
      "Iteration 13, loss = 0.04915218\n",
      "Iteration 14, loss = 0.04672495\n",
      "Iteration 15, loss = 0.03983423\n",
      "Iteration 16, loss = 0.03854841\n",
      "Iteration 17, loss = 0.04062014\n",
      "Iteration 18, loss = 0.04305524\n",
      "Iteration 19, loss = 0.04594666\n",
      "Iteration 20, loss = 0.07867991\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.70027001\n",
      "Iteration 2, loss = 0.11694901\n",
      "Iteration 3, loss = 0.07190544\n",
      "Iteration 4, loss = 0.05621956\n",
      "Iteration 5, loss = 0.04765382\n",
      "Iteration 6, loss = 0.04603555\n",
      "Iteration 7, loss = 0.04312813\n",
      "Iteration 8, loss = 0.03766753\n",
      "Iteration 9, loss = 0.04086006\n",
      "Iteration 10, loss = 0.03776751\n",
      "Iteration 11, loss = 0.04184429\n",
      "Iteration 12, loss = 0.04441684\n",
      "Iteration 13, loss = 0.04787360\n",
      "Iteration 14, loss = 0.04195322\n",
      "Iteration 15, loss = 0.04781514\n",
      "Iteration 16, loss = 0.04919385\n",
      "Iteration 17, loss = 0.05744931\n",
      "Iteration 18, loss = 0.07221396\n",
      "Iteration 19, loss = 0.08877986\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.69484434\n",
      "Iteration 2, loss = 0.11588195\n",
      "Iteration 3, loss = 0.07211917\n",
      "Iteration 4, loss = 0.05760763\n",
      "Iteration 5, loss = 0.05041965\n",
      "Iteration 6, loss = 0.04869911\n",
      "Iteration 7, loss = 0.04852618\n",
      "Iteration 8, loss = 0.04199731\n",
      "Iteration 9, loss = 0.03982153\n",
      "Iteration 10, loss = 0.03998250\n",
      "Iteration 11, loss = 0.04935879\n",
      "Iteration 12, loss = 0.05631590\n",
      "Iteration 13, loss = 0.05550858\n",
      "Iteration 14, loss = 0.04389624\n",
      "Iteration 15, loss = 0.04234379\n",
      "Iteration 16, loss = 0.03794724\n",
      "Iteration 17, loss = 0.03680201\n",
      "Iteration 18, loss = 0.03880009\n",
      "Iteration 19, loss = 0.04332084\n",
      "Iteration 20, loss = 0.04113247\n",
      "Iteration 21, loss = 0.06021341\n",
      "Iteration 22, loss = 0.05874719\n",
      "Iteration 23, loss = 0.06006374\n",
      "Iteration 24, loss = 0.05561342\n",
      "Iteration 25, loss = 0.05060557\n",
      "Iteration 26, loss = 0.04828017\n",
      "Iteration 27, loss = 0.06307265\n",
      "Iteration 28, loss = 0.05304582\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.71349159\n",
      "Iteration 2, loss = 0.11287308\n",
      "Iteration 3, loss = 0.07114384\n",
      "Iteration 4, loss = 0.06387222\n",
      "Iteration 5, loss = 0.05000160\n",
      "Iteration 6, loss = 0.05385232\n",
      "Iteration 7, loss = 0.06006969\n",
      "Iteration 8, loss = 0.04782586\n",
      "Iteration 9, loss = 0.04562677\n",
      "Iteration 10, loss = 0.03978106\n",
      "Iteration 11, loss = 0.03726109\n",
      "Iteration 12, loss = 0.04369496\n",
      "Iteration 13, loss = 0.04291539\n",
      "Iteration 14, loss = 0.03705934\n",
      "Iteration 15, loss = 0.03435214\n",
      "Iteration 16, loss = 0.03539252\n",
      "Iteration 17, loss = 0.04235441\n",
      "Iteration 18, loss = 0.04484170\n",
      "Iteration 19, loss = 0.05291287\n",
      "Iteration 20, loss = 0.05760398\n",
      "Iteration 21, loss = 0.06585309\n",
      "Iteration 22, loss = 0.05675819\n",
      "Iteration 23, loss = 0.05693023\n",
      "Iteration 24, loss = 0.05168936\n",
      "Iteration 25, loss = 0.04741504\n",
      "Iteration 26, loss = 0.04482216\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.70117832\n",
      "Iteration 2, loss = 0.11061608\n",
      "Iteration 3, loss = 0.07111589\n",
      "Iteration 4, loss = 0.05694218\n",
      "Iteration 5, loss = 0.04835715\n",
      "Iteration 6, loss = 0.04588575\n",
      "Iteration 7, loss = 0.04369103\n",
      "Iteration 8, loss = 0.03994014\n",
      "Iteration 9, loss = 0.03588355\n",
      "Iteration 10, loss = 0.03284499\n",
      "Iteration 11, loss = 0.03262149\n",
      "Iteration 12, loss = 0.03403090\n",
      "Iteration 13, loss = 0.03133507\n",
      "Iteration 14, loss = 0.03257110\n",
      "Iteration 15, loss = 0.03712330\n",
      "Iteration 16, loss = 0.03747766\n",
      "Iteration 17, loss = 0.03902490\n",
      "Iteration 18, loss = 0.03925025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19, loss = 0.05031422\n",
      "Iteration 20, loss = 0.04328346\n",
      "Iteration 21, loss = 0.04956470\n",
      "Iteration 22, loss = 0.06877791\n",
      "Iteration 23, loss = 0.05643571\n",
      "Iteration 24, loss = 0.05323350\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.70839090\n",
      "Iteration 2, loss = 0.11713882\n",
      "Iteration 3, loss = 0.06893674\n",
      "Iteration 4, loss = 0.05489187\n",
      "Iteration 5, loss = 0.05379828\n",
      "Iteration 6, loss = 0.04375576\n",
      "Iteration 7, loss = 0.04396759\n",
      "Iteration 8, loss = 0.04477682\n",
      "Iteration 9, loss = 0.04368534\n",
      "Iteration 10, loss = 0.04089750\n",
      "Iteration 11, loss = 0.03640162\n",
      "Iteration 12, loss = 0.03496709\n",
      "Iteration 13, loss = 0.04143342\n",
      "Iteration 14, loss = 0.03783835\n",
      "Iteration 15, loss = 0.03718044\n",
      "Iteration 16, loss = 0.04267609\n",
      "Iteration 17, loss = 0.04365723\n",
      "Iteration 18, loss = 0.04230891\n",
      "Iteration 19, loss = 0.04774177\n",
      "Iteration 20, loss = 0.04837961\n",
      "Iteration 21, loss = 0.05191288\n",
      "Iteration 22, loss = 0.05278862\n",
      "Iteration 23, loss = 0.05024611\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.71234389\n",
      "Iteration 2, loss = 0.11986252\n",
      "Iteration 3, loss = 0.07149113\n",
      "Iteration 4, loss = 0.06164422\n",
      "Iteration 5, loss = 0.06213627\n",
      "Iteration 6, loss = 0.04404044\n",
      "Iteration 7, loss = 0.04162208\n",
      "Iteration 8, loss = 0.03507195\n",
      "Iteration 9, loss = 0.04498629\n",
      "Iteration 10, loss = 0.04268204\n",
      "Iteration 11, loss = 0.03769343\n",
      "Iteration 12, loss = 0.03812340\n",
      "Iteration 13, loss = 0.04053599\n",
      "Iteration 14, loss = 0.03532980\n",
      "Iteration 15, loss = 0.04651234\n",
      "Iteration 16, loss = 0.04952943\n",
      "Iteration 17, loss = 0.04839896\n",
      "Iteration 18, loss = 0.04641676\n",
      "Iteration 19, loss = 0.05553958\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.70246139\n",
      "Iteration 2, loss = 0.11076381\n",
      "Iteration 3, loss = 0.06783825\n",
      "Iteration 4, loss = 0.05549567\n",
      "Iteration 5, loss = 0.05591106\n",
      "Iteration 6, loss = 0.05170662\n",
      "Iteration 7, loss = 0.04742685\n",
      "Iteration 8, loss = 0.04192609\n",
      "Iteration 9, loss = 0.04257762\n",
      "Iteration 10, loss = 0.03676153\n",
      "Iteration 11, loss = 0.03823293\n",
      "Iteration 12, loss = 0.04044385\n",
      "Iteration 13, loss = 0.04763773\n",
      "Iteration 14, loss = 0.04183039\n",
      "Iteration 15, loss = 0.04949750\n",
      "Iteration 16, loss = 0.04091288\n",
      "Iteration 17, loss = 0.04889661\n",
      "Iteration 18, loss = 0.03687007\n",
      "Iteration 19, loss = 0.03803760\n",
      "Iteration 20, loss = 0.03586165\n",
      "Iteration 21, loss = 0.03464790\n",
      "Iteration 22, loss = 0.03274709\n",
      "Iteration 23, loss = 0.03048546\n",
      "Iteration 24, loss = 0.03543648\n",
      "Iteration 25, loss = 0.03926025\n",
      "Iteration 26, loss = 0.03822808\n",
      "Iteration 27, loss = 0.04998054\n",
      "Iteration 28, loss = 0.07110974\n",
      "Iteration 29, loss = 0.06003903\n",
      "Iteration 30, loss = 0.05982540\n",
      "Iteration 31, loss = 0.05169067\n",
      "Iteration 32, loss = 0.05299096\n",
      "Iteration 33, loss = 0.04762036\n",
      "Iteration 34, loss = 0.05026881\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.69753304\n",
      "Iteration 2, loss = 0.10557920\n",
      "Iteration 3, loss = 0.07008391\n",
      "Iteration 4, loss = 0.05781324\n",
      "Iteration 5, loss = 0.06524406\n",
      "Iteration 6, loss = 0.04848829\n",
      "Iteration 7, loss = 0.04495538\n",
      "Iteration 8, loss = 0.03966128\n",
      "Iteration 9, loss = 0.05141429\n",
      "Iteration 10, loss = 0.03938315\n",
      "Iteration 11, loss = 0.04041459\n",
      "Iteration 12, loss = 0.03834687\n",
      "Iteration 13, loss = 0.04216254\n",
      "Iteration 14, loss = 0.05691297\n",
      "Iteration 15, loss = 0.04555843\n",
      "Iteration 16, loss = 0.04856352\n",
      "Iteration 17, loss = 0.04454447\n",
      "Iteration 18, loss = 0.04340463\n",
      "Iteration 19, loss = 0.04566523\n",
      "Iteration 20, loss = 0.04593276\n",
      "Iteration 21, loss = 0.04951635\n",
      "Iteration 22, loss = 0.04476922\n",
      "Iteration 23, loss = 0.04307487\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.69830837\n",
      "Iteration 2, loss = 0.11087549\n",
      "Iteration 3, loss = 0.08321076\n",
      "Iteration 4, loss = 0.05495469\n",
      "Iteration 5, loss = 0.05714832\n",
      "Iteration 6, loss = 0.04349380\n",
      "Iteration 7, loss = 0.04315881\n",
      "Iteration 8, loss = 0.04178201\n",
      "Iteration 9, loss = 0.04695485\n",
      "Iteration 10, loss = 0.04194790\n",
      "Iteration 11, loss = 0.03717722\n",
      "Iteration 12, loss = 0.03779048\n",
      "Iteration 13, loss = 0.03622248\n",
      "Iteration 14, loss = 0.03682334\n",
      "Iteration 15, loss = 0.03558259\n",
      "Iteration 16, loss = 0.03464013\n",
      "Iteration 17, loss = 0.03499903\n",
      "Iteration 18, loss = 0.03631764\n",
      "Iteration 19, loss = 0.06026046\n",
      "Iteration 20, loss = 0.05151499\n",
      "Iteration 21, loss = 0.06009241\n",
      "Iteration 22, loss = 0.06143078\n",
      "Iteration 23, loss = 0.07219342\n",
      "Iteration 24, loss = 0.06914889\n",
      "Iteration 25, loss = 0.06087192\n",
      "Iteration 26, loss = 0.06762767\n",
      "Iteration 27, loss = 0.06084279\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.68227942\n",
      "Iteration 2, loss = 0.11340600\n",
      "Iteration 3, loss = 0.07082737\n",
      "Iteration 4, loss = 0.05771253\n",
      "Iteration 5, loss = 0.05958276\n",
      "Iteration 6, loss = 0.05227687\n",
      "Iteration 7, loss = 0.04300751\n",
      "Iteration 8, loss = 0.04154458\n",
      "Iteration 9, loss = 0.04898663\n",
      "Iteration 10, loss = 0.04381766\n",
      "Iteration 11, loss = 0.04284274\n",
      "Iteration 12, loss = 0.03909274\n",
      "Iteration 13, loss = 0.04692657\n",
      "Iteration 14, loss = 0.04345842\n",
      "Iteration 15, loss = 0.04358659\n",
      "Iteration 16, loss = 0.04219775\n",
      "Iteration 17, loss = 0.04760139\n",
      "Iteration 18, loss = 0.06598441\n",
      "Iteration 19, loss = 0.07510566\n",
      "Iteration 20, loss = 0.06213092\n",
      "Iteration 21, loss = 0.05605749\n",
      "Iteration 22, loss = 0.05044860\n",
      "Iteration 23, loss = 0.04664543\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.70895161\n",
      "Iteration 2, loss = 0.11241774\n",
      "Iteration 3, loss = 0.06383598\n",
      "Iteration 4, loss = 0.05098055\n",
      "Iteration 5, loss = 0.04850771\n",
      "Iteration 6, loss = 0.04271483\n",
      "Iteration 7, loss = 0.04743635\n",
      "Iteration 8, loss = 0.04314158\n",
      "Iteration 9, loss = 0.04194932\n",
      "Iteration 10, loss = 0.03701299\n",
      "Iteration 11, loss = 0.04168962\n",
      "Iteration 12, loss = 0.04309905\n",
      "Iteration 13, loss = 0.04518647\n",
      "Iteration 14, loss = 0.04885674\n",
      "Iteration 15, loss = 0.04366318\n",
      "Iteration 16, loss = 0.04149438\n",
      "Iteration 17, loss = 0.04351617\n",
      "Iteration 18, loss = 0.04868317\n",
      "Iteration 19, loss = 0.04190260\n",
      "Iteration 20, loss = 0.04399448\n",
      "Iteration 21, loss = 0.04712748\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.73154407\n",
      "Iteration 2, loss = 0.11823901\n",
      "Iteration 3, loss = 0.07287148\n",
      "Iteration 4, loss = 0.05656288\n",
      "Iteration 5, loss = 0.05256377\n",
      "Iteration 6, loss = 0.04735446\n",
      "Iteration 7, loss = 0.05017820\n",
      "Iteration 8, loss = 0.04513163\n",
      "Iteration 9, loss = 0.04493068\n",
      "Iteration 10, loss = 0.04050612\n",
      "Iteration 11, loss = 0.04599643\n",
      "Iteration 12, loss = 0.04616412\n",
      "Iteration 13, loss = 0.04297809\n",
      "Iteration 14, loss = 0.03973382\n",
      "Iteration 15, loss = 0.04051050\n",
      "Iteration 16, loss = 0.04626082\n",
      "Iteration 17, loss = 0.06413514\n",
      "Iteration 18, loss = 0.07108131\n",
      "Iteration 19, loss = 0.05950249\n",
      "Iteration 20, loss = 0.05744528\n",
      "Iteration 21, loss = 0.04674216\n",
      "Iteration 22, loss = 0.04323773\n",
      "Iteration 23, loss = 0.04197687\n",
      "Iteration 24, loss = 0.03881850\n",
      "Iteration 25, loss = 0.03767463\n",
      "Iteration 26, loss = 0.03930103\n",
      "Iteration 27, loss = 0.04736673\n",
      "Iteration 28, loss = 0.04142635\n",
      "Iteration 29, loss = 0.04117815\n",
      "Iteration 30, loss = 0.03743757\n",
      "Iteration 31, loss = 0.04195431\n",
      "Iteration 32, loss = 0.04262854\n",
      "Iteration 33, loss = 0.04019960\n",
      "Iteration 34, loss = 0.04051325\n",
      "Iteration 35, loss = 0.04334760\n",
      "Iteration 36, loss = 0.04030432\n",
      "Iteration 37, loss = 0.04474658\n",
      "Iteration 38, loss = 0.05866744\n",
      "Iteration 39, loss = 0.07868673\n",
      "Iteration 40, loss = 0.06749696\n",
      "Iteration 41, loss = 0.06245085\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.72613362\n",
      "Iteration 2, loss = 0.11819503\n",
      "Iteration 3, loss = 0.07064217\n",
      "Iteration 4, loss = 0.05755931\n",
      "Iteration 5, loss = 0.04956169\n",
      "Iteration 6, loss = 0.04649331\n",
      "Iteration 7, loss = 0.05075608\n",
      "Iteration 8, loss = 0.04658464\n",
      "Iteration 9, loss = 0.04378191\n",
      "Iteration 10, loss = 0.04084759\n",
      "Iteration 11, loss = 0.04784163\n",
      "Iteration 12, loss = 0.04388069\n",
      "Iteration 13, loss = 0.04588716\n",
      "Iteration 14, loss = 0.05375009\n",
      "Iteration 15, loss = 0.04842507\n",
      "Iteration 16, loss = 0.05671139\n",
      "Iteration 17, loss = 0.06854328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 18, loss = 0.07388853\n",
      "Iteration 19, loss = 0.07433662\n",
      "Iteration 20, loss = 0.05984040\n",
      "Iteration 21, loss = 0.05190926\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.71525835\n",
      "Iteration 2, loss = 0.11313608\n",
      "Iteration 3, loss = 0.07142911\n",
      "Iteration 4, loss = 0.05390368\n",
      "Iteration 5, loss = 0.04591341\n",
      "Iteration 6, loss = 0.04394883\n",
      "Iteration 7, loss = 0.05319521\n",
      "Iteration 8, loss = 0.04666650\n",
      "Iteration 9, loss = 0.04114685\n",
      "Iteration 10, loss = 0.03630954\n",
      "Iteration 11, loss = 0.03694703\n",
      "Iteration 12, loss = 0.03302328\n",
      "Iteration 13, loss = 0.03634113\n",
      "Iteration 14, loss = 0.03298703\n",
      "Iteration 15, loss = 0.03349769\n",
      "Iteration 16, loss = 0.04047851\n",
      "Iteration 17, loss = 0.04282269\n",
      "Iteration 18, loss = 0.05083626\n",
      "Iteration 19, loss = 0.05276155\n",
      "Iteration 20, loss = 0.04939899\n",
      "Iteration 21, loss = 0.04433957\n",
      "Iteration 22, loss = 0.04687019\n",
      "Iteration 23, loss = 0.04112107\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.70894760\n",
      "Iteration 2, loss = 0.11807770\n",
      "Iteration 3, loss = 0.06877168\n",
      "Iteration 4, loss = 0.05442877\n",
      "Iteration 5, loss = 0.04694886\n",
      "Iteration 6, loss = 0.03965409\n",
      "Iteration 7, loss = 0.04713256\n",
      "Iteration 8, loss = 0.03964660\n",
      "Iteration 9, loss = 0.03900301\n",
      "Iteration 10, loss = 0.04019386\n",
      "Iteration 11, loss = 0.04986565\n",
      "Iteration 12, loss = 0.03989038\n",
      "Iteration 13, loss = 0.04843241\n",
      "Iteration 14, loss = 0.03887938\n",
      "Iteration 15, loss = 0.03951835\n",
      "Iteration 16, loss = 0.05685658\n",
      "Iteration 17, loss = 0.06823096\n",
      "Iteration 18, loss = 0.06727314\n",
      "Iteration 19, loss = 0.08844073\n",
      "Iteration 20, loss = 0.06162636\n",
      "Iteration 21, loss = 0.05290342\n",
      "Iteration 22, loss = 0.04737232\n",
      "Iteration 23, loss = 0.04411676\n",
      "Iteration 24, loss = 0.04148930\n",
      "Iteration 25, loss = 0.03938164\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.69476228\n",
      "Iteration 2, loss = 0.12160388\n",
      "Iteration 3, loss = 0.06795612\n",
      "Iteration 4, loss = 0.05956609\n",
      "Iteration 5, loss = 0.05639014\n",
      "Iteration 6, loss = 0.04880486\n",
      "Iteration 7, loss = 0.04805919\n",
      "Iteration 8, loss = 0.04772877\n",
      "Iteration 9, loss = 0.04258710\n",
      "Iteration 10, loss = 0.03860905\n",
      "Iteration 11, loss = 0.05166631\n",
      "Iteration 12, loss = 0.04542169\n",
      "Iteration 13, loss = 0.04416760\n",
      "Iteration 14, loss = 0.03891646\n",
      "Iteration 15, loss = 0.03681976\n",
      "Iteration 16, loss = 0.04621345\n",
      "Iteration 17, loss = 0.04072356\n",
      "Iteration 18, loss = 0.03878219\n",
      "Iteration 19, loss = 0.03923541\n",
      "Iteration 20, loss = 0.04768672\n",
      "Iteration 21, loss = 0.04051790\n",
      "Iteration 22, loss = 0.04135979\n",
      "Iteration 23, loss = 0.03906254\n",
      "Iteration 24, loss = 0.04217657\n",
      "Iteration 25, loss = 0.04387155\n",
      "Iteration 26, loss = 0.05436315\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.70072891\n",
      "Iteration 2, loss = 0.12431411\n",
      "Iteration 3, loss = 0.06711172\n",
      "Iteration 4, loss = 0.05844362\n",
      "Iteration 5, loss = 0.05216476\n",
      "Iteration 6, loss = 0.04851196\n",
      "Iteration 7, loss = 0.04176795\n",
      "Iteration 8, loss = 0.03902825\n",
      "Iteration 9, loss = 0.03740088\n",
      "Iteration 10, loss = 0.03792994\n",
      "Iteration 11, loss = 0.05137335\n",
      "Iteration 12, loss = 0.04853589\n",
      "Iteration 13, loss = 0.05338578\n",
      "Iteration 14, loss = 0.05530084\n",
      "Iteration 15, loss = 0.04784236\n",
      "Iteration 16, loss = 0.04975596\n",
      "Iteration 17, loss = 0.05547943\n",
      "Iteration 18, loss = 0.05745763\n",
      "Iteration 19, loss = 0.06050214\n",
      "Iteration 20, loss = 0.05771216\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  70 out of  70 | elapsed: 63.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.68741033\n",
      "Iteration 2, loss = 0.12452603\n",
      "Iteration 3, loss = 0.07360807\n",
      "Iteration 4, loss = 0.06243809\n",
      "Iteration 5, loss = 0.05084584\n",
      "Iteration 6, loss = 0.04665181\n",
      "Iteration 7, loss = 0.04717662\n",
      "Iteration 8, loss = 0.04026544\n",
      "Iteration 9, loss = 0.04645368\n",
      "Iteration 10, loss = 0.04082447\n",
      "Iteration 11, loss = 0.04022806\n",
      "Iteration 12, loss = 0.03999551\n",
      "Iteration 13, loss = 0.04143804\n",
      "Iteration 14, loss = 0.03697980\n",
      "Iteration 15, loss = 0.03967916\n",
      "Iteration 16, loss = 0.04655990\n",
      "Iteration 17, loss = 0.05266580\n",
      "Iteration 18, loss = 0.05878768\n",
      "Iteration 19, loss = 0.05576820\n",
      "Iteration 20, loss = 0.05747663\n",
      "Iteration 21, loss = 0.05962791\n",
      "Iteration 22, loss = 0.05915528\n",
      "Iteration 23, loss = 0.06095213\n",
      "Iteration 24, loss = 0.06365177\n",
      "Iteration 25, loss = 0.06663278\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=MLPClassifier(activation='logistic', alpha=1e-05,\n",
       "                                     batch_size='auto', beta_1=0.9,\n",
       "                                     beta_2=0.999, early_stopping=False,\n",
       "                                     epsilon=1e-08, hidden_layer_sizes=(3,),\n",
       "                                     learning_rate='constant',\n",
       "                                     learning_rate_init=0.1, max_fun=15000,\n",
       "                                     max_iter=200, momentum=0.9,\n",
       "                                     n_iter_no_change=10,\n",
       "                                     nesterovs_momentum=True, power_t=0.5,\n",
       "                                     random_state=1, shuffle=True,\n",
       "                                     solver='adam', tol=0.0001,\n",
       "                                     validation_fraction=0.1, verbose=True,\n",
       "                                     warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'hidden_layer_sizes': [(3,), (6,), (9,), (12,), (15,),\n",
       "                                                (18,), (21,)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the grid (start the grid search):\n",
    "grid.fit(X_test_dtm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is:  0.8821319882480546\n",
      "best parameter is:  {'hidden_layer_sizes': (21,)}\n"
     ]
    }
   ],
   "source": [
    "print(\"best score is: \", grid.best_score_)\n",
    "print(\"best parameter is: \", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
